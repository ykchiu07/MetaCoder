================================================================================
專案內容匯出報告 (根目錄: /home/yk/文件/GitHub/MetaCoder/src)
================================================================================


#################### 檔案: MetaCoder.py ####################
import os
import json
import sys
import tkinter as tk

# 設定模組搜尋路徑，確保能 import 子資料夾中的模組
sys.path.append(os.path.join(os.path.dirname(__file__), 'Generate'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Dynamic'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Static'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'System'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'GUI'))
# Backend Imports
from ProjectManager import ProjectManager
from CodeImplementer import CodeImplementer
from TestSpawner import TestSpawner
from ChaosSpawner import ChaosSpawner
from MetricCollector import MetricCollector
from RuntimeAnalyst import RuntimeAnalyst
from ChaosExecuter import ChaosExecuter
from VersionController import VersionController
from StructureAnalyzer import StructureAnalyzer
from OllamaManager import OllamaManager

# Frontend Import
from MainWindow import MainWindow

class MetaCoder:
    def __init__(self, workspace_root: str = "./vibe_workspace"):
        self.workspace_root = os.path.abspath(workspace_root)
        # [Fix 5] 設定檔路徑
        self.config_path = os.path.join(self.workspace_root, "vibe_config.json")

        # 預設設定
        self.model_config = {
            "architect": "gemma3:12b",
            "coder": "gemma3:12b",
            "analyst": "gemma3:12b",
            "vision": "gemma3:4b"
        }

        # 嘗試載入設定 (如果存在)
        self._load_config()

        # 初始化子系統 (保持不變)
        self.vc = VersionController(self.workspace_root)
        self.pm = ProjectManager(self.workspace_root)
        self.coder = CodeImplementer()
        self.tester = TestSpawner()
        self.chaos_spawner = ChaosSpawner()
        self.chaos_runner = ChaosExecuter(self.workspace_root)
        self.collector = MetricCollector()
        self.analyst = RuntimeAnalyst()
        self.static_analyzer = StructureAnalyzer(self.workspace_root)

        self.current_architecture_path = None
        # [Fix 3] 初始化 Ollama Manager
        self.ollama_mgr = OllamaManager()

    # --- [Fix 3] Ollama 控制 API ---
    def ensure_ollama_started(self):
        """在生成前呼叫"""
        self.ollama_mgr.set_logger(lambda msg: print(msg)) # 或導向 GUI log
        self.ollama_mgr.start_service()

    def kill_ollama(self):
        """在 Stop 時呼叫"""
        self.ollama_mgr.kill_service()

    # --- [Fix 5] 設定持久化 ---
    def _load_config(self):
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r') as f:
                    saved = json.load(f)
                    self.model_config.update(saved.get('models', {}))
            except: pass

    def run(self):
        """啟動 GUI 主迴圈"""
        root = tk.Tk()
        # 將自己 (Controller) 傳入 GUI (View)
        app = MainWindow(root, self)
        root.mainloop()

    # --- 設定管理 ---
    def update_model_config(self, role: str, model_name: str):
        if role in self.model_config:
            self.model_config[role] = model_name
            # 立即存檔
            with open(self.config_path, 'w') as f:
                json.dump({'models': self.model_config}, f, indent=4)
            print(f"[Meta] Model for {role} updated to {model_name} and saved.")

    # --- [Fix 2] Main.py Spec 處理 ---
    def _create_main_entry_spec(self, entry_point_name: str):
        if not entry_point_name: return

        # 獲取專案根目錄
        if not self.current_architecture_path: return
        project_dir = os.path.dirname(self.current_architecture_path)

        # 為了讓 ProjectExplorer 能掃描到，我們建立一個名為 "main" 的資料夾
        # 這樣它就會被視為一個模組
        main_mod_dir = os.path.join(project_dir, "main")
        if not os.path.exists(main_mod_dir): os.makedirs(main_mod_dir)

        spec_path = os.path.join(main_mod_dir, "spec.json")

        if not os.path.exists(spec_path):
            spec_data = {
                "module_name": "main", # 邏輯名稱
                "description": "Application Entry Point",
                "dependencies": [], # Main 可能依賴所有人，這裡先空著或填入所有模組
                "functions": [
                    {
                        "name": "main",
                        "args": [],
                        "return_type": "None",
                        "docstring": "Application entry point."
                    }
                ]
            }
            # 嘗試填入所有其他模組作為依賴
            try:
                with open(self.current_architecture_path, 'r') as f:
                    arch = json.load(f)
                spec_data['dependencies'] = [m['name'] for m in arch.get('modules', [])]
            except: pass

            with open(spec_path, 'w', encoding='utf-8') as f:
                json.dump(spec_data, f, indent=4)

            # 建立真實檔案 (放在 main/main.py 或者根目錄 main.py?)
            # 為了符合 Vibe-Coder 的「一模組一資料夾」邏輯，我們放在 main/main.py
            # 但使用者可能期待根目錄。這裡我們做個妥協：放在 main/main.py
            # 之後打包時再處理。
            with open(os.path.join(main_mod_dir, "main.py"), 'w') as f:
                f.write("def main():\n    print('Hello Vibe-Coder')\n\nif __name__ == '__main__':\n    main()")

    # --- Phase 1: 架構生成 ---
    def init_project(self, requirements: str):
        model = self.model_config["architect"]
        print(f"[Meta] Initializing project with {model}...")

        result = self.pm.generateHighStructure(requirements, model)
        self.current_architecture_path = result.structure_file_path

        # [Fix 6] 讀取架構檔，檢查是否有 entry_point 並生成 spec
        try:
            with open(self.current_architecture_path, 'r') as f:
                arch = json.load(f)
            entry = arch.get('entry_point')
            if entry:
                self._create_main_entry_spec(entry)
        except Exception as e:
            print(f"[Meta] Error handling entry point: {e}")

        self.vc.archiveVersion(f"Init Project: {requirements[:20]}")
        return result

    # --- Phase 2: 模組細化 ---
    def refine_module(self, module_name: str, cancel_event=None):
        if not self.current_architecture_path: raise ValueError("No architecture.")

        # 1. [Check] 檢查被依賴模組是否已細化 (Spec 存在)
        deps = self._get_module_dependencies_from_arch(module_name)
        project_dir = os.path.dirname(self.current_architecture_path)

        for dep in deps:
            dep_spec = os.path.join(project_dir, dep, "spec.json")
            if not os.path.exists(dep_spec):
                print(f"[Refine Blocked] Dependency '{dep}' is not refined yet.")
                return None # 這裡應該在 GUI 顯示錯誤，透過 return None 告知失敗

        # 2. [Generate] 生成 Spec
        # 先存檔當前狀態 (Snapshot)，以便回滾
        # 但 VersionController 是基於 git commit。
        # 策略：生成 -> 檢查 -> 若通過則 Commit，若失敗則 Revert 檔案。
        # 為了能 Revert，我們需要知道改了什麼，或者依賴 git clean。
        # 簡單做法：先 Commit 當前狀態為 "Pre-Refine backup" (可選)，或者只在失敗時 checkout .

        model = self.model_config["architect"]
        progress = {'status': '', 'current': 0, 'total': 0}

        result = self.pm.generateModuleDetail(
            self.current_architecture_path, module_name, progress, model, cancel_event
        )
        if not result: return None # 被取消或失敗

        # 3. [Audit] 虛擬靜態分析：循環依賴檢查
        print(f"[Meta] Auditing circular dependencies for {module_name}...")

        # 構建虛擬代碼 Map (所有已存在的 Spec + 剛生成的這個)
        virtual_map = {}
        # 讀取所有現有模組
        for d in os.listdir(project_dir):
            spec_p = os.path.join(project_dir, d, "spec.json")
            if os.path.exists(spec_p):
                with open(spec_p, 'r') as f:
                    s = json.load(f)
                    # 轉換為 import 語句
                    imports = "\n".join([f"import {dep}" for dep in s.get('dependencies', [])])
                    virtual_map[d] = imports

        cycles = self.static_analyzer.detect_cycles_from_stubs(virtual_map)

        if cycles:
            print(f"[Audit Failed] Circular dependency detected: {cycles}")
            # [Rollback] 刪除剛生成的 spec 和 stub
            # 最快的方法是 git checkout -- <module_dir> (如果之前有 commit)
            # 或者手動刪除。這裡使用 VC 的 rollback file (需擴充支援資料夾) 或簡單用 os.remove
            # 由於這是新生成的檔案，它們是 Untracked。
            # 我們可以直接刪除該模組資料夾下的 spec.json 和 .py
            import shutil
            mod_dir = os.path.dirname(result.spec_file_path)
            shutil.rmtree(mod_dir) # 危險：如果該資料夾原本就有東西？
            # 安全做法：只刪除 spec.json 和 __init__.py
            os.remove(result.spec_file_path)
            # ... (刪除 stubs)
            print(f"[Meta] Rolled back refinement for {module_name}.")
            return None # 視為失敗

        # 4. [Commit] 通過檢查，歸檔
        self.vc.archiveVersion(f"Refined Module: {module_name}")
        return result

    # --- Phase 3: 函式實作 ---
    def implement_functions(self, spec_path: str, func_names: list, cancel_event=None):
        # 1. [Generate]
        model = self.model_config["coder"]
        # 強制單線程
        results = self.coder.generateFunctionCode(spec_path, func_names, model, max_workers=1, cancel_event=cancel_event)

        if not results: return []

        # 2. [Audit] 實作一致性檢查
        # 讀取 Spec 中的允許依賴
        with open(spec_path, 'r') as f:
            spec = json.load(f)
        allowed = spec.get('dependencies', [])
        # 允許依賴自己模組
        mod_name = spec.get('module_name')
        if mod_name: allowed.append(mod_name)

        valid_results = []
        for res in results:
            if not res.success: continue

            # 檢查
            if self.static_analyzer.verify_implementation_deps(res.file_path, allowed):
                valid_results.append(res)
            else:
                print(f"[Audit Failed] Implementation of {res.function_name} violates dependency rules.")
                # [Rollback] 還原該檔案
                # 這裡簡單清空或寫回 pass stub
                with open(res.file_path, 'w') as f:
                    f.write(f"def {res.function_name}(*args, **kwargs):\n    raise NotImplementedError('Audit Failed: Dependency Violation')")
                # 更新狀態為 failed
                self.coder._update_status_file(os.path.dirname(spec_path), res.function_name, "audit_failed", 0, 0)

        # 3. [Commit]
        if valid_results:
            self.vc.archiveVersion(f"Implemented {len(valid_results)} funcs in {os.path.basename(os.path.dirname(spec_path))}")

        return valid_results

    # --- 測試生成 ---
    def generate_tests(self, spec_path: str, func_names: list):
        """生成單元測試"""
        model = self.model_config["coder"] # 寫測試也算 Coding
        return self.tester.generateUnitTest(spec_path, func_names, model)

    # --- 動態分析與除錯 ---
    def run_dynamic_analysis(self, code_str: str, target_func: str):
        """執行代碼 -> 收集數據 -> LLM 分析"""
        print("[Meta] Starting Dynamic Analysis...")

        # 1. 執行並收集 (LLM-free)
        self.collector.execute_code(code_str)
        raw_json = self.collector.outputMetricResult(target_funcs=[target_func])
        data = json.loads(raw_json)

        # 2. 邏輯瓶頸分析
        model_logic = self.model_config["analyst"]
        logic_report, l_entropy = self.analyst.analyzeBottleNeck(
            target_func,
            data['performance'],
            data['io_activity'],
            data['code_coverage'],
            data['call_graph'],
            logic_model=model_logic
        )

        # 3. 視覺分析 (如果有截圖)
        vision_report = "No GUI detected or captured."
        v_entropy = 0.0

        if data.get('gui_screenshots'):
            model_vision = self.model_config["vision"]
            # 取第一張截圖進行分析
            snapshot_path = data['gui_screenshots'][0]
            vision_report, v_entropy = self.analyst.analyzeSnapshot(
                snapshot_path,
                f"Function context: {target_func}",
                "Auto-analysis: Check for visual anomalies.",
                vision_model=model_vision
            )

        return {
            "metrics": data,
            "logic_report": logic_report,
            "vision_report": vision_report,
            "entropies": (l_entropy, v_entropy)
        }

    # --- 混沌工程 ---
    def run_chaos_campaign(self, module_name: str):
        """弱點分析 -> 生成計畫 -> 執行攻擊"""
        model = self.model_config["analyst"]

        # 1. 分析
        weakness_path, _ = self.chaos_spawner.generateWeaknessAnalysis(
            module_name, self.workspace_root, model
        )
        # 2. 計畫
        plan_path, _ = self.chaos_spawner.generateChaosPlan(
            weakness_path, 2, model # Focus Level 2 (Medium+)
        )
        # 3. 執行
        report_path = self.chaos_runner.produceChaos(module_name)
        return report_path

    # --- 系統操作 ---
    def get_project_tree(self):
        """
        [修正] 更強健的 architecture.json 搜尋邏輯。
        """
        # 1. 如果已經有快取路徑且檔案存在，直接用
        if self.current_architecture_path and os.path.exists(self.current_architecture_path):
            try:
                with open(self.current_architecture_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except: pass # 讀取失敗則重搜

        # 2. 搜尋邏輯：優先找根目錄，其次找第一層子目錄
        candidates = []
        # Check root
        p = os.path.join(self.workspace_root, "architecture.json")
        if os.path.exists(p): candidates.append(p)

        # Check subdirs (depth=1)
        if not candidates:
            for d in os.listdir(self.workspace_root):
                full_d = os.path.join(self.workspace_root, d)
                if os.path.isdir(full_d):
                    p = os.path.join(full_d, "architecture.json")
                    if os.path.exists(p): candidates.append(p)

        if candidates:
            self.current_architecture_path = candidates[0] # 取第一個找到的
            try:
                with open(self.current_architecture_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[Meta] Error reading arch json: {e}")
                return {}

        return {}

    # --- [Fix 1] 依賴圖邏輯 ---
    def get_module_dependencies(self):
        """
        優先從 architecture.json 讀取依賴關係 (因為這是 Phase 1 就有的)。
        如果沒有 arch 檔，才退回到 StaticAnalyzer 分析源碼。
        """
        # 嘗試讀取架構檔
        arch_data = self.get_project_tree()

        nodes = []
        edges = [] # (source, target)

        if arch_data and 'modules' in arch_data:
            # 方案 A: 使用架構定義 (Intent)
            for mod in arch_data['modules']:
                name = mod['name']
                nodes.append(name)
                for dep in mod.get('dependencies', []):
                    edges.append((name, dep))

            # 把 main entry 也加進去
            entry = arch_data.get('entry_point')
            if entry:
                # 假設 entry (如 main.py) 依賴所有模組，或者在 arch 中未定義
                # 這裡我們先把 main 當作一個節點
                main_node = "main" # 簡化顯示
                if main_node not in nodes: nodes.append(main_node)
                # 通常 main 依賴所有頂層模組，這裡暫不畫線，以免太亂，或者全畫

        else:
            # 方案 B: 退回源碼分析 (Reality)
            if not self.static_analyzer.dependencies:
                self.static_analyzer._preprocess()
            nodes = list(self.static_analyzer.internal_modules)
            for src, targets in self.static_analyzer.dependencies.items():
                for tgt in targets:
                    if tgt in nodes:
                        edges.append((src, tgt))

        return nodes, edges

    def _get_module_dependencies_from_arch(self, module_name):
        """從 architecture.json 讀取依賴列表"""
        if not self.current_architecture_path: return []
        with open(self.current_architecture_path, 'r') as f:
            arch = json.load(f)
        mod = next((m for m in arch.get('modules', []) if m['name'] == module_name), None)
        return mod.get('dependencies', []) if mod else []

    def get_function_distribution(self):
        """
        [修正] 聚合模組名稱，解決 Legend 過於破碎的問題。
        將 'auth.login', 'auth.utils' 統一聚合為 'auth'。
        """
        if not self.static_analyzer.graphs:
            self.static_analyzer._preprocess()

        distribution = {} # { 'module_folder_name': [func_names...] }

        for mod_key, graph in self.static_analyzer.graphs.items():
            # mod_key 可能是 "auth.login" 或 "main"
            # 我們只取最頂層的模組名稱 (即資料夾名稱)
            # 如果是 'auth.login' -> top_mod = 'auth'
            # 如果是 'main' -> top_mod = 'main'
            top_mod = mod_key.split('.')[0]

            # 排除一些非業務邏輯的根節點 (視情況而定，這裡先保留)

            funcs = []
            for _, data in graph.graph.nodes(data=True):
                if data.get('type') == 'function':
                    funcs.append(data.get('name'))

            if funcs:
                if top_mod not in distribution:
                    distribution[top_mod] = []
                # 合併並去重
                distribution[top_mod].extend(funcs)
                # distribution[top_mod] = list(set(distribution[top_mod])) # 若有需要去重

        return distribution

    def set_workspace(self, new_path: str):
        print(f"[Meta] Switching workspace to: {new_path}")
        self.workspace_root = os.path.abspath(new_path)
        self.config_path = os.path.join(self.workspace_root, "vibe_config.json")

        self.vc = VersionController(self.workspace_root)
        self.pm = ProjectManager(self.workspace_root)
        self.static_analyzer = StructureAnalyzer(self.workspace_root)
        self.chaos_runner = ChaosExecuter(self.workspace_root)
        self.current_architecture_path = None

        self._load_config() # 載入該 Workspace 的特定設定
        self.get_project_tree()
        print("[Meta] Workspace reset complete.")

    def check_dependencies_met(self, module_name: str) -> bool:
        """
        [新增] 檢查某模組的依賴是否都已經實作完畢。
        規則：依賴模組必須至少有一個函式被標記為 implemented。
        """
        if not self.current_architecture_path: return True

        try:
            with open(self.current_architecture_path, 'r') as f:
                arch = json.load(f)

            mod_info = next((m for m in arch.get('modules', []) if m['name'] == module_name), None)
            if not mod_info: return True

            project_dir = os.path.dirname(self.current_architecture_path)

            for dep in mod_info.get('dependencies', []):
                # 檢查依賴模組的 status.json
                status_path = os.path.join(project_dir, dep, ".status.json")
                if not os.path.exists(status_path):
                    print(f"[Dependency Check] {module_name} blocked: Dependency '{dep}' has no status file.")
                    return False

                # 檢查是否有任何 implemented 的函式
                with open(status_path, 'r') as f:
                    status = json.load(f)
                    # 簡單檢查：只要有任何 key 的 status 是 implemented 就算通過
                    # 更嚴謹的檢查需要依賴細粒度的 function call graph，這裡先做模組級檢查
                    if not any(v.get('status') == 'implemented' for v in status.values()):
                        print(f"[Dependency Check] {module_name} blocked: Dependency '{dep}' has no implemented functions.")
                        return False

            return True

        except Exception as e:
            print(f"[Dependency Check] Error: {e}")
            return True # 出錯時預設不擋，以免死鎖

if __name__ == "__main__":
    app = MetaCoder()
    app.run()

######################################################################

#################### 檔案: project_content_export.txt ####################
================================================================================
專案內容匯出報告 (根目錄: /home/yk/文件/GitHub/MetaCoder/src)
================================================================================


#################### 檔案: MetaCoder.py ####################
import os
import json
import sys
import tkinter as tk

# 設定模組搜尋路徑，確保能 import 子資料夾中的模組
sys.path.append(os.path.join(os.path.dirname(__file__), 'Generate'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Dynamic'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'Static'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'System'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'GUI'))
# Backend Imports
from ProjectManager import ProjectManager
from CodeImplementer import CodeImplementer
from TestSpawner import TestSpawner
from ChaosSpawner import ChaosSpawner
from MetricCollector import MetricCollector
from RuntimeAnalyst import RuntimeAnalyst
from ChaosExecuter import ChaosExecuter
from VersionController import VersionController
from StructureAnalyzer import StructureAnalyzer
from OllamaManager import OllamaManager

# Frontend Import
from MainWindow import MainWindow

class MetaCoder:
    def __init__(self, workspace_root: str = "./vibe_workspace"):
        self.workspace_root = os.path.abspath(workspace_root)
        # [Fix 5] 設定檔路徑
        self.config_path = os.path.join(self.workspace_root, "vibe_config.json")

        # 預設設定
        self.model_config = {
            "architect": "gemma3:12b",
            "coder": "gemma3:12b",
            "analyst": "gemma3:12b",
            "vision": "gemma3:4b"
        }

        # 嘗試載入設定 (如果存在)
        self._load_config()

        # 初始化子系統 (保持不變)
        self.vc = VersionController(self.workspace_root)
        self.pm = ProjectManager(self.workspace_root)
        self.coder = CodeImplementer()
        self.tester = TestSpawner()
        self.chaos_spawner = ChaosSpawner()
        self.chaos_runner = ChaosExecuter(self.workspace_root)
        self.collector = MetricCollector()
        self.analyst = RuntimeAnalyst()
        self.static_analyzer = StructureAnalyzer(self.workspace_root)

        self.current_architecture_path = None
        # [Fix 3] 初始化 Ollama Manager
        self.ollama_mgr = OllamaManager()

    # --- [Fix 3] Ollama 控制 API ---
    def ensure_ollama_started(self):
        """在生成前呼叫"""
        self.ollama_mgr.set_logger(lambda msg: print(msg)) # 或導向 GUI log
        self.ollama_mgr.start_service()

    def kill_ollama(self):
        """在 Stop 時呼叫"""
        self.ollama_mgr.kill_service()

    # --- [Fix 5] 設定持久化 ---
    def _load_config(self):
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r') as f:
                    saved = json.load(f)
                    self.model_config.update(saved.get('models', {}))
            except: pass

    def run(self):
        """啟動 GUI 主迴圈"""
        root = tk.Tk()
        # 將自己 (Controller) 傳入 GUI (View)
        app = MainWindow(root, self)
        root.mainloop()

    # --- 設定管理 ---
    def update_model_config(self, role: str, model_name: str):
        if role in self.model_config:
            self.model_config[role] = model_name
            # 立即存檔
            with open(self.config_path, 'w') as f:
                json.dump({'models': self.model_config}, f, indent=4)
            print(f"[Meta] Model for {role} updated to {model_name} and saved.")

    # --- [Fix 2] Main.py Spec 處理 ---
    def _create_main_entry_spec(self, entry_point_name: str):
        if not entry_point_name: return

        # 獲取專案根目錄
        if not self.current_architecture_path: return
        project_dir = os.path.dirname(self.current_architecture_path)

        # 為了讓 ProjectExplorer 能掃描到，我們建立一個名為 "main" 的資料夾
        # 這樣它就會被視為一個模組
        main_mod_dir = os.path.join(project_dir, "main")
        if not os.path.exists(main_mod_dir): os.makedirs(main_mod_dir)

        spec_path = os.path.join(main_mod_dir, "spec.json")

        if not os.path.exists(spec_path):
            spec_data = {
                "module_name": "main", # 邏輯名稱
                "description": "Application Entry Point",
                "dependencies": [], # Main 可能依賴所有人，這裡先空著或填入所有模組
                "functions": [
                    {
                        "name": "main",
                        "args": [],
                        "return_type": "None",
                        "docstring": "Application entry point."
                    }
                ]
            }
            # 嘗試填入所有其他模組作為依賴
            try:
                with open(self.current_architecture_path, 'r') as f:
                    arch = json.load(f)
                spec_data['dependencies'] = [m['name'] for m in arch.get('modules', [])]
            except: pass

            with open(spec_path, 'w', encoding='utf-8') as f:
                json.dump(spec_data, f, indent=4)

            # 建立真實檔案 (放在 main/main.py 或者根目錄 main.py?)
            # 為了符合 Vibe-Coder 的「一模組一資料夾」邏輯，我們放在 main/main.py
            # 但使用者可能期待根目錄。這裡我們做個妥協：放在 main/main.py
            # 之後打包時再處理。
            with open(os.path.join(main_mod_dir, "main.py"), 'w') as f:
                f.write("def main():\n    print('Hello Vibe-Coder')\n\nif __name__ == '__main__':\n    main()")

    # --- Phase 1: 架構生成 ---
    def init_project(self, requirements: str):
        model = self.model_config["architect"]
        print(f"[Meta] Initializing project with {model}...")

        result = self.pm.generateHighStructure(requirements, model)
        self.current_architecture_path = result.structure_file_path

        # [Fix 6] 讀取架構檔，檢查是否有 entry_point 並生成 spec
        try:
            with open(self.current_architecture_path, 'r') as f:
                arch = json.load(f)
            entry = arch.get('entry_point')
            if entry:
                self._create_main_entry_spec(entry)
        except Exception as e:
            print(f"[Meta] Error handling entry point: {e}")

        self.vc.archiveVersion(f"Init Project: {requirements[:20]}")
        return result

    # --- Phase 2: 模組細化 ---
    def refine_module(self, module_name: str, cancel_event=None):
        if not self.current_architecture_path: raise ValueError("No architecture.")

        # 1. [Check] 檢查被依賴模組是否已細化 (Spec 存在)
        deps = self._get_module_dependencies_from_arch(module_name)
        project_dir = os.path.dirname(self.current_architecture_path)

        for dep in deps:
            dep_spec = os.path.join(project_dir, dep, "spec.json")
            if not os.path.exists(dep_spec):
                print(f"[Refine Blocked] Dependency '{dep}' is not refined yet.")
                return None # 這裡應該在 GUI 顯示錯誤，透過 return None 告知失敗

        # 2. [Generate] 生成 Spec
        # 先存檔當前狀態 (Snapshot)，以便回滾
        # 但 VersionController 是基於 git commit。
        # 策略：生成 -> 檢查 -> 若通過則 Commit，若失敗則 Revert 檔案。
        # 為了能 Revert，我們需要知道改了什麼，或者依賴 git clean。
        # 簡單做法：先 Commit 當前狀態為 "Pre-Refine backup" (可選)，或者只在失敗時 checkout .

        model = self.model_config["architect"]
        progress = {'status': '', 'current': 0, 'total': 0}

        result = self.pm.generateModuleDetail(
            self.current_architecture_path, module_name, progress, model, cancel_event
        )
        if not result: return None # 被取消或失敗

        # 3. [Audit] 虛擬靜態分析：循環依賴檢查
        print(f"[Meta] Auditing circular dependencies for {module_name}...")

        # 構建虛擬代碼 Map (所有已存在的 Spec + 剛生成的這個)
        virtual_map = {}
        # 讀取所有現有模組
        for d in os.listdir(project_dir):
            spec_p = os.path.join(project_dir, d, "spec.json")
            if os.path.exists(spec_p):
                with open(spec_p, 'r') as f:
                    s = json.load(f)
                    # 轉換為 import 語句
                    imports = "\n".join([f"import {dep}" for dep in s.get('dependencies', [])])
                    virtual_map[d] = imports

        cycles = self.static_analyzer.detect_cycles_from_stubs(virtual_map)

        if cycles:
            print(f"[Audit Failed] Circular dependency detected: {cycles}")
            # [Rollback] 刪除剛生成的 spec 和 stub
            # 最快的方法是 git checkout -- <module_dir> (如果之前有 commit)
            # 或者手動刪除。這裡使用 VC 的 rollback file (需擴充支援資料夾) 或簡單用 os.remove
            # 由於這是新生成的檔案，它們是 Untracked。
            # 我們可以直接刪除該模組資料夾下的 spec.json 和 .py
            import shutil
            mod_dir = os.path.dirname(result.spec_file_path)
            shutil.rmtree(mod_dir) # 危險：如果該資料夾原本就有東西？
            # 安全做法：只刪除 spec.json 和 __init__.py
            os.remove(result.spec_file_path)
            # ... (刪除 stubs)
            print(f"[Meta] Rolled back refinement for {module_name}.")
            return None # 視為失敗

        # 4. [Commit] 通過檢查，歸檔
        self.vc.archiveVersion(f"Refined Module: {module_name}")
        return result

    # --- Phase 3: 函式實作 ---
    def implement_functions(self, spec_path: str, func_names: list, cancel_event=None):
        # 1. [Generate]
        model = self.model_config["coder"]
        # 強制單線程
        results = self.coder.generateFunctionCode(spec_path, func_names, model, max_workers=1, cancel_event=cancel_event)

        if not results: return []

        # 2. [Audit] 實作一致性檢查
        # 讀取 Spec 中的允許依賴
        with open(spec_path, 'r') as f:
            spec = json.load(f)
        allowed = spec.get('dependencies', [])
        # 允許依賴自己模組
        mod_name = spec.get('module_name')
        if mod_name: allowed.append(mod_name)

        valid_results = []
        for res in results:
            if not res.success: continue

            # 檢查
            if self.static_analyzer.verify_implementation_deps(res.file_path, allowed):
                valid_results.append(res)
            else:
                print(f"[Audit Failed] Implementation of {res.function_name} violates dependency rules.")
                # [Rollback] 還原該檔案
                # 這裡簡單清空或寫回 pass stub
                with open(res.file_path, 'w') as f:
                    f.write(f"def {res.function_name}(*args, **kwargs):\n    raise NotImplementedError('Audit Failed: Dependency Violation')")
                # 更新狀態為 failed
                self.coder._update_status_file(os.path.dirname(spec_path), res.function_name, "audit_failed", 0, 0)

        # 3. [Commit]
        if valid_results:
            self.vc.archiveVersion(f"Implemented {len(valid_results)} funcs in {os.path.basename(os.path.dirname(spec_path))}")

        return valid_results

    # --- 測試生成 ---
    def generate_tests(self, spec_path: str, func_names: list):
        """生成單元測試"""
        model = self.model_config["coder"] # 寫測試也算 Coding
        return self.tester.generateUnitTest(spec_path, func_names, model)

    # --- 動態分析與除錯 ---
    def run_dynamic_analysis(self, code_str: str, target_func: str):
        """執行代碼 -> 收集數據 -> LLM 分析"""
        print("[Meta] Starting Dynamic Analysis...")

        # 1. 執行並收集 (LLM-free)
        self.collector.execute_code(code_str)
        raw_json = self.collector.outputMetricResult(target_funcs=[target_func])
        data = json.loads(raw_json)

        # 2. 邏輯瓶頸分析
        model_logic = self.model_config["analyst"]
        logic_report, l_entropy = self.analyst.analyzeBottleNeck(
            target_func,
            data['performance'],
            data['io_activity'],
            data['code_coverage'],
            data['call_graph'],
            logic_model=model_logic
        )

        # 3. 視覺分析 (如果有截圖)
        vision_report = "No GUI detected or captured."
        v_entropy = 0.0

        if data.get('gui_screenshots'):
            model_vision = self.model_config["vision"]
            # 取第一張截圖進行分析
            snapshot_path = data['gui_screenshots'][0]
            vision_report, v_entropy = self.analyst.analyzeSnapshot(
                snapshot_path,
                f"Function context: {target_func}",
                "Auto-analysis: Check for visual anomalies.",
                vision_model=model_vision
            )

        return {
            "metrics": data,
            "logic_report": logic_report,
            "vision_report": vision_report,
            "entropies": (l_entropy, v_entropy)
        }

    # --- 混沌工程 ---
    def run_chaos_campaign(self, module_name: str):
        """弱點分析 -> 生成計畫 -> 執行攻擊"""
        model = self.model_config["analyst"]

        # 1. 分析
        weakness_path, _ = self.chaos_spawner.generateWeaknessAnalysis(
            module_name, self.workspace_root, model
        )
        # 2. 計畫
        plan_path, _ = self.chaos_spawner.generateChaosPlan(
            weakness_path, 2, model # Focus Level 2 (Medium+)
        )
        # 3. 執行
        report_path = self.chaos_runner.produceChaos(module_name)
        return report_path

    # --- 系統操作 ---
    def get_project_tree(self):
        """
        [修正] 更強健的 architecture.json 搜尋邏輯。
        """
        # 1. 如果已經有快取路徑且檔案存在，直接用
        if self.current_architecture_path and os.path.exists(self.current_architecture_path):
            try:
                with open(self.current_architecture_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except: pass # 讀取失敗則重搜

        # 2. 搜尋邏輯：優先找根目錄，其次找第一層子目錄
        candidates = []
        # Check root
        p = os.path.join(self.workspace_root, "architecture.json")
        if os.path.exists(p): candidates.append(p)

        # Check subdirs (depth=1)
        if not candidates:
            for d in os.listdir(self.workspace_root):
                full_d = os.path.join(self.workspace_root, d)
                if os.path.isdir(full_d):
                    p = os.path.join(full_d, "architecture.json")
                    if os.path.exists(p): candidates.append(p)

        if candidates:
            self.current_architecture_path = candidates[0] # 取第一個找到的
            try:
                with open(self.current_architecture_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[Meta] Error reading arch json: {e}")
                return {}

        return {}

    # --- [Fix 1] 依賴圖邏輯 ---
    def get_module_dependencies(self):
        """
        優先從 architecture.json 讀取依賴關係 (因為這是 Phase 1 就有的)。
        如果沒有 arch 檔，才退回到 StaticAnalyzer 分析源碼。
        """
        # 嘗試讀取架構檔
        arch_data = self.get_project_tree()

        nodes = []
        edges = [] # (source, target)

        if arch_data and 'modules' in arch_data:
            # 方案 A: 使用架構定義 (Intent)
            for mod in arch_data['modules']:
                name = mod['name']
                nodes.append(name)
                for dep in mod.get('dependencies', []):
                    edges.append((name, dep))

            # 把 main entry 也加進去
            entry = arch_data.get('entry_point')
            if entry:
                # 假設 entry (如 main.py) 依賴所有模組，或者在 arch 中未定義
                # 這裡我們先把 main 當作一個節點
                main_node = "main" # 簡化顯示
                if main_node not in nodes: nodes.append(main_node)
                # 通常 main 依賴所有頂層模組，這裡暫不畫線，以免太亂，或者全畫

        else:
            # 方案 B: 退回源碼分析 (Reality)
            if not self.static_analyzer.dependencies:
                self.static_analyzer._preprocess()
            nodes = list(self.static_analyzer.internal_modules)
            for src, targets in self.static_analyzer.dependencies.items():
                for tgt in targets:
                    if tgt in nodes:
                        edges.append((src, tgt))

        return nodes, edges

    def _get_module_dependencies_from_arch(self, module_name):
        """從 architecture.json 讀取依賴列表"""
        if not self.current_architecture_path: return []
        with open(self.current_architecture_path, 'r') as f:
            arch = json.load(f)
        mod = next((m for m in arch.get('modules', []) if m['name'] == module_name), None)
        return mod.get('dependencies', []) if mod else []

    def get_function_distribution(self):
        """
        [修正] 聚合模組名稱，解決 Legend 過於破碎的問題。
        將 'auth.login', 'auth.utils' 統一聚合為 'auth'。
        """
        if not self.static_analyzer.graphs:
            self.static_analyzer._preprocess()

        distribution = {} # { 'module_folder_name': [func_names...] }

        for mod_key, graph in self.static_analyzer.graphs.items():
            # mod_key 可能是 "auth.login" 或 "main"
            # 我們只取最頂層的模組名稱 (即資料夾名稱)
            # 如果是 'auth.login' -> top_mod = 'auth'
            # 如果是 'main' -> top_mod = 'main'
            top_mod = mod_key.split('.')[0]

            # 排除一些非業務邏輯的根節點 (視情況而定，這裡先保留)

            funcs = []
            for _, data in graph.graph.nodes(data=True):
                if data.get('type') == 'function':
                    funcs.append(data.get('name'))

            if funcs:
                if top_mod not in distribution:
                    distribution[top_mod] = []
                # 合併並去重
                distribution[top_mod].extend(funcs)
                # distribution[top_mod] = list(set(distribution[top_mod])) # 若有需要去重

        return distribution

    def set_workspace(self, new_path: str):
        print(f"[Meta] Switching workspace to: {new_path}")
        self.workspace_root = os.path.abspath(new_path)
        self.config_path = os.path.join(self.workspace_root, "vibe_config.json")

        self.vc = VersionController(self.workspace_root)
        self.pm = ProjectManager(self.workspace_root)
        self.static_analyzer = StructureAnalyzer(self.workspace_root)
        self.chaos_runner = ChaosExecuter(self.workspace_root)
        self.current_architecture_path = None

        self._load_config() # 載入該 Workspace 的特定設定
        self.get_project_tree()
        print("[Meta] Workspace reset complete.")

    def check_dependencies_met(self, module_name: str) -> bool:
        """
        [新增] 檢查某模組的依賴是否都已經實作完畢。
        規則：依賴模組必須至少有一個函式被標記為 implemented。
        """
        if not self.current_architecture_path: return True

        try:
            with open(self.current_architecture_path, 'r') as f:
                arch = json.load(f)

            mod_info = next((m for m in arch.get('modules', []) if m['name'] == module_name), None)
            if not mod_info: return True

            project_dir = os.path.dirname(self.current_architecture_path)

            for dep in mod_info.get('dependencies', []):
                # 檢查依賴模組的 status.json
                status_path = os.path.join(project_dir, dep, ".status.json")
                if not os.path.exists(status_path):
                    print(f"[Dependency Check] {module_name} blocked: Dependency '{dep}' has no status file.")
                    return False

                # 檢查是否有任何 implemented 的函式
                with open(status_path, 'r') as f:
                    status = json.load(f)
                    # 簡單檢查：只要有任何 key 的 status 是 implemented 就算通過
                    # 更嚴謹的檢查需要依賴細粒度的 function call graph，這裡先做模組級檢查
                    if not any(v.get('status') == 'implemented' for v in status.values()):
                        print(f"[Dependency Check] {module_name} blocked: Dependency '{dep}' has no implemented functions.")
                        return False

            return True

        except Exception as e:
            print(f"[Dependency Check] Error: {e}")
            return True # 出錯時預設不擋，以免死鎖

if __name__ == "__main__":
    app = MetaCoder()
    app.run()

######################################################################

#################### 檔案: copy_files.py ####################
import os
import io

def export_project_content(root_dir=".", output_filename="project_content_export.txt"):
    """
    遍歷指定資料夾，將所有檔案內容匯出到單一文字檔案中。

    Args:
        root_dir (str): 專案的根目錄。
        output_filename (str): 輸出的文字檔案名稱。
    """
    # 指定要跳過的資料夾名稱
    EXCLUDE_DIRS = ['__pycache__', 'vibe_workspace']
    # 指定要跳過的隱藏資料夾（以 '.' 開頭）
    EXCLUDE_PREFIX = ('.',)

    print(f"正在從 '{root_dir}' 開始掃描專案...")

    # 使用 io.open 確保寫入時的編碼處理
    with io.open(output_filename, 'w', encoding='utf-8') as outfile:

        # 寫入檔頭，作為內容分隔
        outfile.write("=" * 80 + "\n")
        outfile.write(f"專案內容匯出報告 (根目錄: {os.path.abspath(root_dir)})\n")
        outfile.write("=" * 80 + "\n\n")

        # os.walk(top, topdown=True, onerror=None, followlinks=False)
        # topdown=True 允許我們在遍歷前修改 dirs
        for dirpath, dirnames, filenames in os.walk(root_dir, topdown=True):

            # --- 排除資料夾處理 ---

            # 遍歷 dirnames 的副本，以便在迭代時修改原始的 dirnames 列表
            # 這樣 os.walk 就不會進入這些資料夾
            dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS and not d.startswith(EXCLUDE_PREFIX)]

            # 檢查當前路徑是否在排除列表中，如果不是根目錄，且以排除前綴開頭，則跳過
            if dirpath != root_dir and os.path.basename(dirpath).startswith(EXCLUDE_PREFIX):
                continue

            # --- 檔案內容處理 ---

            # 過濾掉非 Python 檔案或你不想匯出的檔案（這裡只排除隱藏檔案）
            filenames = [f for f in filenames if not f.startswith(EXCLUDE_PREFIX)]

            for filename in filenames:
                file_path = os.path.join(dirpath, filename)

                # 忽略腳本本身
                if file_path == output_filename or file_path == os.path.basename(__file__):
                    continue

                try:
                    # 寫入檔案路徑作為分隔線
                    relative_path = os.path.relpath(file_path, root_dir)
                    outfile.write("\n" + "#" * 20 + f" 檔案: {relative_path} " + "#" * 20 + "\n")

                    # 讀取檔案內容
                    with io.open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                        content = infile.read()
                        outfile.write(content)

                    outfile.write("\n" + "#" * 70 + "\n") # 檔案內容結束分隔線

                except Exception as e:
                    # 處理讀取錯誤（例如二進位檔案或編碼問題）
                    outfile.write(f"\n[無法讀取檔案 {file_path}，錯誤: {e}]\n")
                    outfile.write("#" * 70 + "\n")

    print(f"\n✅ 匯出完成！內容已儲存至 '{output_filename}'。")
    print(f"現在你可以複製 '{output_filename}' 的內容貼給我了。")


if __name__ == "__main__":
    # 執行函數，預設掃描當前目錄
    export_project_content(root_dir=".")

######################################################################

#################### 檔案: Generate/CodeImplementer.py ####################
import os
import json
import time
import re
from typing import List, Dict, Any
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
from OllamaClient import OllamaClient

import threading # 新增引用

@dataclass
class ImplementationResult:
    function_name: str
    file_path: str
    model_entropy: float
    duration: float
    success: bool

class CodeImplementer:
    def __init__(self, ollama_url: str = "http://localhost:11434"):
        self.client = OllamaClient(ollama_url)



    def _extract_python_code(self, text: str) -> str:
        # 優先匹配 ```python ... ```
        match = re.search(r"```python\s*(.*?)\s*```", text, re.DOTALL)
        if match: return match.group(1)
        # 其次匹配 ``` ... ```
        match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
        if match: return match.group(1)
        return text

    def _get_dependency_context(self, module_dir: str, spec_data: Dict) -> str:
        """
        [新增] 讀取專案架構與依賴模組的 Spec，組合出 Context。
        """
        try:
            # 假設結構: workspace/project/module/
            project_dir = os.path.dirname(module_dir)
            arch_path = os.path.join(project_dir, "architecture.json")

            if not os.path.exists(arch_path): return ""

            with open(arch_path, 'r') as f: arch = json.load(f)

            current_mod_name = os.path.basename(module_dir)
            target_mod_info = next((m for m in arch.get('modules', []) if m['name'] == current_mod_name), None)

            if not target_mod_info: return ""

            dependencies = target_mod_info.get('dependencies', [])
            context = "EXTERNAL DEPENDENCIES:\n"

            for dep_name in dependencies:
                dep_spec_path = os.path.join(project_dir, dep_name, "spec.json")
                if os.path.exists(dep_spec_path):
                    with open(dep_spec_path, 'r') as f:
                        dep_spec = json.load(f)
                        # 簡化 spec 資訊以節省 token
                        funcs = [f"{f['name']}({', '.join([a['name'] for a in f.get('args',[])])})" for f in dep_spec.get('functions', [])]
                        context += f"- Module '{dep_name}': Available Functions: {', '.join(funcs)}\n"

            return context
        except Exception as e:
            print(f"Error building context: {e}")
            return ""

    def _update_status_file(self, module_dir: str, func_name: str, status: str, entropy: float, version: int):
        """[修正] 紀錄詳細資訊到 .status.json"""
        status_path = os.path.join(module_dir, ".status.json")
        data = {}
        if os.path.exists(status_path):
            try:
                with open(status_path, 'r') as f: data = json.load(f)
            except: pass

        data[func_name] = {
            "status": status,
            "entropy": entropy,
            "version": version,
            "timestamp": time.time()
        }

        with open(status_path, 'w') as f:
            json.dump(data, f, indent=4)

    def _get_next_version(self, module_dir: str, func_name: str) -> int:
        status_path = os.path.join(module_dir, ".status.json")
        if os.path.exists(status_path):
            try:
                with open(status_path, 'r') as f:
                    data = json.load(f)
                    if func_name in data and isinstance(data[func_name], dict):
                        return data[func_name].get("version", 0) + 1
            except: pass
        return 1

    def _implement_single_function(self, spec_data: Dict, func_name: str, module_dir: str, model_name: str, feedback_report: str, cancel_event) -> ImplementationResult:
        start_time = time.time()
        filename = "__init_logic__.py" if func_name == "__init__" else f"{func_name}.py"
        target_path = os.path.join(module_dir, filename)

        # 1. 準備 Context
        target_func_spec = next((f for f in spec_data.get('functions', []) if f['name'] == func_name), None)
        module_name = spec_data.get('module_name', 'unknown')

        # [新增] 依賴注入
        dep_context = self._get_dependency_context(module_dir, spec_data)

        func_signature = (
            f"Function: {func_name}\n"
            f"Args: {target_func_spec.get('args')}\n"
            f"Return: {target_func_spec.get('return_type')}\n"
            f"Doc: {target_func_spec.get('docstring')}"
        )

        system_prompt = (
            "You are an expert Python Developer. Implement the function based on the spec.\n"
            "RULES:\n"
            "1. Use the provided EXTERNAL DEPENDENCIES to make correct import calls.\n"
            "2. If importing from a sibling module, use relative imports (e.g. `from ..utils import helper`).\n"
            "3. Handle edge cases and errors.\n"
            "4. Output ONLY Python code."
        )

        user_prompt = (
            f"MODULE: {module_name}\n"
            f"{dep_context}\n"
            f"TARGET SPEC:\n{func_signature}\n\n"
            "Implement this function."
        )

        if feedback_report: # Fix mode logic (省略，保持原樣但加入 dep_context)
             user_prompt = f"FIX REQUEST:\n{feedback_report}\n\n" + user_prompt

        # 2. 生成
        try:
            content_str, entropy = self.client.chat_complete_raw(model_name, system_prompt, user_prompt, cancel_event=cancel_event)
            code_body = self._extract_python_code(content_str)

            # 簡單修補 import (如果 LLM 沒寫)
            if "import" not in code_body:
                code_body = "from typing import Any, List, Dict, Optional\n" + code_body

            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(code_body)

            # 3. 更新狀態
            version = self._get_next_version(module_dir, func_name)
            self._update_status_file(module_dir, func_name, "implemented", entropy, version)

            return ImplementationResult(func_name, target_path, entropy, time.time() - start_time, True, version)

        except InterruptedError:
            return ImplementationResult(func_name, target_path, 0.0, 0.0, False)
        except Exception as e:
            print(f"Error: {e}")
            return ImplementationResult(func_name, target_path, -1.0, 0.0, False)

    # 這裡修改 generateFunctionCode 簽名以支援 feedback_report 字典
    def generateFunctionCode(
        self,
        spec_path: str,
        target_function_names: List[str],
        model_name: str= "gemma3:12b",
        max_workers: int = 3,
        feedback_map: Dict[str, str] = None,  # [新增] Key: func_name, Value: report_string
        cancel_event: threading.Event = None  # [新增] 接收取消旗標
    ) -> List[ImplementationResult]:

        if not os.path.exists(spec_path):
            raise FileNotFoundError(f"Spec file not found: {spec_path}")

        with open(spec_path, 'r', encoding='utf-8') as f:
            spec_data = json.load(f)

        module_dir = os.path.dirname(spec_path)
        results = []
        feedback_map = feedback_map or {}

        print(f"[*] Starting implementation for {len(target_function_names)} functions with {max_workers} workers...")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_name = {}
            for name in target_function_names:
                if cancel_event and cancel_event.is_set():
                    break
                report = feedback_map.get(name)
                # [關鍵] 將 cancel_event 傳入 _implement_single_function
                future = executor.submit(
                    self._implement_single_function,
                    spec_data, name, module_dir, model_name, report, cancel_event
                )
                future_to_name[future] = name

            for future in as_completed(future_to_name):
                # 這裡不 break，讓正在跑的任務有機會完成或拋出 InterruptedError
                try:
                    res = future.result()
                    results.append(res)
                except InterruptedError:
                    print(f"   [Stopped] {future_to_name[future]}")
                except Exception as e:
                    print(f"   [Error] {future_to_name[future]}: {e}")
                action = "Fixed" if feedback_map.get(res.function_name) else "Implemented"
                status = "Success" if res.success else "Failed"
                print(f"    [{action}] {res.function_name}: {status} (Entropy: {res.model_entropy})")

        return results

    def implement_function_direct(self, spec_path: str, func_name: str, model_name: str, cancel_event=None) -> ImplementationResult:
            with open(spec_path, 'r') as f: spec_data = json.load(f)
            module_dir = os.path.dirname(spec_path)
            return self._implement_single_function(spec_data, func_name, module_dir, model_name, None, cancel_event)

######################################################################

#################### 檔案: Generate/OllamaClient.py ####################
import requests
import json
import os
import base64
from typing import Dict, Tuple, Optional, List, Any

class OllamaClient:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url

    def _calculate_entropy(self, raw_response: Dict) -> float:
        # (保持原有的 entropy 計算邏輯不變)
        try:
            # 如果是 stream 模式，logprobs 可能分散在不同 chunks，這裡簡化處理
            # 針對非 stream 的完整回應計算
            logprobs_list = raw_response.get('logprobs')
            if logprobs_list is None and 'message' in raw_response:
                logprobs_list = raw_response['message'].get('logprobs')
            if not logprobs_list: return -1.0
            total_logprob = 0.0
            count = 0
            for item in logprobs_list:
                lp = item.get('logprob')
                if lp is not None:
                    total_logprob += lp
                    count += 1
            if count == 0: return 0.0
            return round(-(total_logprob / count), 4)
        except Exception:
            return -1.0

    def chat_complete_json(self, model: str, system_prompt: str, user_prompt: str, temperature: float = 0.2, cancel_event=None) -> Tuple[Dict, float, Dict]:
        """
        [修正] 支援 cancel_event 的 JSON 請求
        """
        # 為了支援中斷，我們必須用 stream=True，然後自己組裝字串
        # 但 JSON 模式通常比較快，且 Ollama 支援 format='json'
        # 這裡示範如何用 stream 攔截

        payload = {
            "model": model,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            "format": "json",
            "stream": True, # [關鍵] 開啟串流
            "options": {"temperature": temperature, "num_ctx": 4096},
            "logprobs": False # Stream 模式下 logprobs 處理較複雜，暫時關閉以提升穩定性
        }

        full_content = ""
        try:
            with requests.post(f"{self.base_url}/api/chat", json=payload, stream=True) as response:
                response.raise_for_status()
                for line in response.iter_lines():
                    # [關鍵] 每次讀取一行都檢查取消旗標
                    if cancel_event and cancel_event.is_set():
                        print("[Ollama] Request cancelled by user.")
                        raise InterruptedError("Task Cancelled")

                    if line:
                        chunk = json.loads(line)
                        if 'message' in chunk:
                            content = chunk['message'].get('content', '')
                            full_content += content

            # 嘗試解析最後組裝好的 JSON
            parsed_json = json.loads(full_content)
            return parsed_json, 0.0, {} # Stream 模式暫不計算 Entropy

        except InterruptedError:
            raise # 拋出給上層處理
        except Exception as e:
            print(f"[OllamaClient JSON Error] {e}")
            return {}, -1.0, {}

    def chat_complete_raw(
        self,
        model: str,
        system_prompt: str,
        user_prompt: str,
        temperature: float = 0.3,
        images: Optional[List[str]] = None,
        cancel_event=None
    ) -> Tuple[str, float]:
        """
        [修正] 支援 cancel_event 的原始文字請求 (Stream Mode)
        """
        b64_images = []
        if images:
            for img_path in images:
                if os.path.exists(img_path):
                    try:
                        with open(img_path, "rb") as image_file:
                            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                            b64_images.append(encoded_string)
                    except Exception as e:
                        print(f"[OllamaClient] Failed to encode image {img_path}: {e}")

        user_msg = {"role": "user", "content": user_prompt}
        if b64_images: user_msg["images"] = b64_images

        payload = {
            "model": model,
            "messages": [{"role": "system", "content": system_prompt}, user_msg],
            "stream": True, # [關鍵] 開啟串流
            "options": {"temperature": temperature}
        }

        full_content = ""
        try:
            # 使用 stream=True
            with requests.post(f"{self.base_url}/api/chat", json=payload, stream=True, timeout=60) as response:
                response.raise_for_status()

                # [Fix 1] 使用 iter_lines 並設定 chunk_size，確保能頻繁進入迴圈檢查 cancel
                # 注意：Ollama 的 stream 回應是按行傳送 JSON 物件的
                for line in response.iter_lines():

                    # [Fix 1] 每次迭代都檢查
                    if cancel_event and cancel_event.is_set():
                        print("[Ollama] Request cancelled by user.")
                        # 這裡我們直接 return，requests 的 context manager 會自動關閉連線 (TCP close)
                        # 這通常足以讓 Ollama Server 停止生成 (Broken Pipe)
                        raise InterruptedError("Task Cancelled")

                    if line:
                        try:
                            chunk = json.loads(line)
                            if 'message' in chunk:
                                content = chunk['message'].get('content', '')
                                full_content += content
                                # if chunk.get('done'): break
                        except: pass

            return full_content, 0.0

        except InterruptedError:
            # 拋出讓上層捕捉
            raise
        except Exception as e:
            # Timeout 或其他網絡錯誤
            if cancel_event and cancel_event.is_set():
                raise InterruptedError("Task Cancelled")
            print(f"[OllamaClient Raw Error] {e}")
            return f"Error: {str(e)}", -1.0

######################################################################

#################### 檔案: Generate/ChaosSpawner.py ####################
import os
import json
import time
from typing import Dict, List, Any, Tuple
from OllamaClient import OllamaClient

class ChaosSpawner:
    def __init__(self, ollama_url: str = "http://localhost:11434"):
        self.client = OllamaClient(ollama_url)

    def _extract_json(self, text: str) -> Dict:
        """嘗試從 LLM 回應中提取 JSON"""
        import re
        try:
            # 優先尋找 markdown json block
            match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
            if match:
                return json.loads(match.group(1))
            # 其次嘗試直接解析
            return json.loads(text)
        except json.JSONDecodeError:
            print(f"[ChaosSpawner] JSON Parse Error. Raw text: {text[:100]}...")
            return {}

    def generateWeaknessAnalysis(
        self,
        module_name: str,
        project_root: str,  # 傳入專案根目錄以便尋找模組
        model_name: str = "gemma3:12b"
    ) -> Tuple[str, float]:
        """
        [Phase 1] 弱點掃描：分析模組內函式的職責，評估崩潰風險。
        """
        module_dir = os.path.join(project_root, module_name)
        spec_path = os.path.join(module_dir, "spec.json")

        if not os.path.exists(spec_path):
            return f"Error: Spec not found at {spec_path}", 0.0

        print(f"[*] [ChaosSpawner] Analyzing weakness for '{module_name}'...")

        # 1. 讀取規格
        with open(spec_path, 'r', encoding='utf-8') as f:
            spec_data = json.load(f)

        # 2. 構建 Prompt
        # 我們只提供函式簽名與描述，不提供程式碼，讓模型從架構層面判斷
        funcs_summary = []
        for f in spec_data.get('functions', []):
            funcs_summary.append({
                "name": f['name'],
                "args": [a['name'] for a in f.get('args', [])],
                "desc": f.get('docstring', '')
            })

        system_prompt = (
            "You are a Chaos Engineering Architect. "
            "Analyze the provided functions and estimate their 'Vulnerability Level' to faults "
            "(e.g., IO failures, timeout, bad input).\n"
            "\n"
            "RATING CRITERIA:\n"
            "- HIGH: Functions involving File IO, Network, DB, or Complex State Mutation.\n"
            "- MEDIUM: Functions with complex logic loops or conditional branches.\n"
            "- LOW: Pure utility functions, simple getters/setters.\n"
            "\n"
            "Output strictly valid JSON format:\n"
            "{\n"
            "  'module_name': 'str',\n"
            "  'analysis': [\n"
            "    {'function': 'func_name', 'level': 'High/Medium/Low', 'reason': 'Brief explanation'}\n"
            "  ]\n"
            "}"
        )

        user_prompt = (
            f"MODULE: {module_name}\n"
            f"FUNCTIONS: {json.dumps(funcs_summary, indent=2)}\n\n"
            "Perform vulnerability analysis."
        )

        # 3. 呼叫 LLM
        content_str, entropy = self.client.chat_complete_json(model_name, system_prompt, user_prompt)

        # 4. 存檔
        output_path = os.path.join(module_dir, "weakness_analysis.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(content_str, f, indent=4, ensure_ascii=False)

        return output_path, entropy

    def generateChaosPlan(
        self,
        weakness_path: str,
        focus_level: int,  # 1=Low, 2=Med, 3=High
        model_name: str = "gemma3:12b"
    ) -> Tuple[str, float]:
        """
        [Phase 2] 制定計畫：針對篩選出的函式，讀取原始碼並設計注入策略。
        """
        if not os.path.exists(weakness_path):
            return f"Error: Analysis not found at {weakness_path}", 0.0

        module_dir = os.path.dirname(weakness_path)

        print(f"[*] [ChaosSpawner] Generating Chaos Plan (Level >= {focus_level})...")

        # 1. 讀取分析報告
        with open(weakness_path, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)

        # 等級對照表
        level_map = {"low": 1, "medium": 2, "high": 3}

        # 2. 篩選目標函式並讀取原始碼
        target_funcs_context = []

        for item in analysis_data.get('analysis', []):
            lvl_str = item.get('level', 'Low').lower()
            lvl_int = level_map.get(lvl_str, 1)

            if lvl_int >= focus_level:
                func_name = item['function']
                # 推導實作檔案路徑
                filename = "__init_logic__.py" if func_name == "__init__" else f"{func_name}.py"
                file_path = os.path.join(module_dir, filename)

                code_content = "<missing>"
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        code_content = f.read()

                target_funcs_context.append({
                    "name": func_name,
                    "vulnerability": lvl_str,
                    "source_code": code_content
                })

        if not target_funcs_context:
            return "No functions match the focus level.", 0.0

        # 3. 構建 Prompt：要求生成具體參數
        system_prompt = (
            "You are a Gremlin Chaos Engineer. "
            "Create a specific 'Fault Injection Plan' for the provided Python functions. "
            "For each function, design 3 specific experiments.\n"
            "\n"
            "INJECTION TYPES:\n"
            "1. Exception: Force the function to raise an error (e.g., ValueError, TimeoutError).\n"
            "2. Latency: Inject sleep() to simulate lag.\n"
            "3. DataCorruption: Pass None, empty strings, or huge numbers as arguments.\n"
            "\n"
            "Output strictly valid JSON format:\n"
            "{\n"
            "  'plan_id': 'timestamp',\n"
            "  'experiments': [\n"
            "    {\n"
            "      'target_function': 'func_name',\n"
            "      'injections': [\n"
            "        {'type': 'Exception', 'details': 'Raise FileNotFoundError'},\n"
            "        {'type': 'DataCorruption', 'arg_name': 'x', 'value': 'None'}\n"
            "      ]\n"
            "    }\n"
            "  ]\n"
            "}"
        )

        user_prompt = (
            f"TARGETS (Level >= {focus_level}):\n"
            f"{json.dumps(target_funcs_context, indent=2)}\n\n"
            "Design a chaos test plan based on the source code logic."
        )

        # 4. 呼叫 LLM
        content_str, entropy = self.client.chat_complete_json(model_name, system_prompt, user_prompt)

        # 5. 存檔
        output_path = os.path.join(module_dir, "chaos_plan.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(content_str, f, indent=4, ensure_ascii=False)

        return output_path, entropy

######################################################################

#################### 檔案: Generate/ProjectManager.py ####################
import os
import json
import time
from typing import Dict, Any, List
from dataclasses import dataclass
from OllamaClient import OllamaClient

import threading # 新增引用

@dataclass
class GenerationResult:
    structure_file_path: str
    project_root_path: str
    model_entropy: float
    execution_time: float

@dataclass
class ModuleDetailResult:
    spec_file_path: str
    fragment_files: List[str]
    model_entropy: float

class ProjectManager:
    def __init__(self, workspace_dir: str = "./vibe_workspace", ollama_url: str = "http://localhost:11434"):
        self.workspace_dir = workspace_dir
        self.client = OllamaClient(ollama_url)
        if not os.path.exists(workspace_dir):
            os.makedirs(workspace_dir)

    def generateHighStructure(self, project_requirements: str, model_name: str) -> GenerationResult:
        """(Phase 1) 生成專案總架構並建立資料夾結構"""
        print(f"[*] (Phase 1) Generating Architecture with {model_name}...")
        start_time = time.time()

        system_prompt = (
            "You are an expert Python Software Architect. "
            "Design a modular architecture based on the user's requirements. "
            "\n\n"
            "CRITICAL REQUIREMENTS:\n"
            "1. Define a clear entry point (e.g., 'main.py' or 'app.py') that orchestrates the modules.\n"
            "2. Define strict dependencies. If Module A imports Module B, Module A depends on B.\n"
            "3. Avoid circular dependencies.\n"
            "\n"
            "Output strict JSON:\n"
            "{\n"
            "  'project_name': 'str',\n"
            "  'entry_point': 'main.py',\n"  # 新增
            "  'modules': [\n"
            "    {\n"
            "      'name': 'auth',\n"
            "      'description': 'Handles user login/register',\n"
            "      'dependencies': ['database', 'utils'],\n" # 強制填寫
            "      'public_api_summary': ['login(user, pass)', 'logout()']\n"
            "    }\n"
            "  ]\n"
            "}"
        )

        data, entropy, stats = self.client.chat_complete_json(model_name, system_prompt, f"Req: {project_requirements}")

        project_name = data.get("project_name", "vibe_project").replace(" ", "_")
        project_dir = os.path.join(self.workspace_dir, project_name)
        if not os.path.exists(project_dir): os.makedirs(project_dir)

        arch_path = os.path.join(project_dir, "architecture.json")
        with open(arch_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)

        for mod in data.get('modules', []):
            mod_dir = os.path.join(project_dir, mod['name'])
            if not os.path.exists(mod_dir): os.makedirs(mod_dir)

        return GenerationResult(arch_path, project_dir, entropy, time.time() - start_time)

    def generateModuleDetail(self, architecture_path: str, target_module_name: str, progress_data: Dict[str, Any], model_name: str,cancel_event: threading.Event = None ) -> ModuleDetailResult:
        """
        (Phase 2) 單一模組細化
        **優化重點**：強化參數完整性 Prompt
        """
        print(f"[*] (Phase 2) Refining Module '{target_module_name}' with {model_name}...")

        with open(architecture_path, 'r', encoding='utf-8') as f:
            arch_data = json.load(f)

        # [Fix 4] 提前定義 mod_dir
        project_dir = os.path.dirname(architecture_path)
        mod_dir = os.path.join(project_dir, target_module_name)
        if not os.path.exists(mod_dir): os.makedirs(mod_dir)

        target_mod_info = next((m for m in arch_data.get('modules', []) if m['name'] == target_module_name), None)
        if not target_mod_info: raise ValueError(f"Module '{target_module_name}' not found.")

        declared_deps = target_mod_info.get('dependencies', [])

        # 構建 Context：只提供「被依賴模組」的詳細資訊
        dep_context = "DEPENDENCY CONTEXT (You can use these APIs):\n"
        project_dir = os.path.dirname(architecture_path)

        for dep in declared_deps:
            dep_spec_path = os.path.join(project_dir, dep, "spec.json")
            if os.path.exists(dep_spec_path):
                with open(dep_spec_path, 'r') as f:
                    spec = json.load(f)
                    # 簡化 API 描述
                    funcs = [f"{fn['name']}(...)" for fn in spec.get('functions', [])]
                    dep_context += f"- Module '{dep}': {spec.get('description')}\n  Available: {', '.join(funcs)}\n"
            else:
                dep_context += f"- Module '{dep}': (Spec not generated yet)\n"

        system_prompt = (
            "You are a Senior Python Developer. Define the detailed specification for a module.\n"
            "\n"
            "CRITICAL RULES FOR DEPENDENCIES:\n"
            f"1. This module is architected to depend on: {json.dumps(declared_deps)}.\n"
            "2. You MUST include a 'dependencies' field in the output JSON matching this list.\n"
            "3. In the 'docstring' of each function, explicitly state which external functions it calls (e.g., 'Calls auth.login').\n"
            "\n"
            "Output strict JSON:\n"
            "{\n"
            "  'module_name': 'str',\n"
            "  'dependencies': ['mod_a', 'mod_b'],\n" # 強制欄位
            "  'functions': [\n"
            "    {\n"
            "      'name': 'func_name',\n"
            "      'args': [...],\n"
            "      'return_type': '...',\n"
            "      'docstring': '...'\n"
            "    }\n"
            "  ]\n"
            "}"
        )

        user_prompt = (
            f"PROJECT: {arch_data.get('project_name')}\n"
            f"TARGET MODULE: {target_module_name}\n"
            f"DESCRIPTION: {target_mod_info.get('description')}\n\n"
            f"{dep_context}\n"
            "Generate the full spec.json."
        )

        # 在生成 Spec 之前檢查
        if cancel_event and cancel_event.is_set():
            print("[ProjectManager] Operation Cancelled.")
            return None

        # 呼叫 LLM
        spec_data, entropy, _ = self.client.chat_complete_json(model_name, system_prompt, user_prompt, cancel_event=cancel_event)

        # 強制補全依賴
        if 'dependencies' not in spec_data:
            spec_data['dependencies'] = declared_deps

        # 存檔 (現在 mod_dir 已經定義了)
        spec_path = os.path.join(mod_dir, "spec.json")
        with open(spec_path, 'w', encoding='utf-8') as f:
            json.dump(spec_data, f, indent=4, ensure_ascii=False)

        fragment_paths = []

        for func in spec_data.get('functions', []):
            if cancel_event and cancel_event.is_set():
                print("[ProjectManager] Fragment generation cancelled.")
                break

        # 建立 __init__.py
        init_py_path = os.path.join(mod_dir, "__init__.py")
        with open(init_py_path, 'w', encoding='utf-8') as f:
            f.write(f"# Package marker for {target_module_name}\n")
        fragment_paths.append(init_py_path)

        # [防禦性編程] 強制補全依賴 (以架構定義為準)
        if 'dependencies' not in spec_data:
            spec_data['dependencies'] = declared_deps

        spec_path = os.path.join(mod_dir, "spec.json")
        with open(spec_path, 'w', encoding='utf-8') as f:
            json.dump(spec_data, f, indent=4, ensure_ascii=False)

        # 建立 Stubs
        progress_data['status'] = f"Creating file stubs..."
        for func in spec_data.get('functions', []):
            func_name = func['name']
            filename = "__init_logic__.py" if func_name == "__init__" else f"{func_name}.py"
            file_path = os.path.join(mod_dir, filename)

            args_str = ", ".join([f"{arg['name']}: {arg.get('type', 'Any')}" for arg in func.get('args', [])])
            return_hint = func.get('return_type', 'Any')
            docstring = func.get('docstring', '').replace('\n', '\n    ')

            stub_content = (
                f"from typing import Any, List, Dict, Optional\n\n"
                f"def {func_name}({args_str}) -> {return_hint}:\n"
                f"    \"\"\"\n    {docstring}\n    \"\"\"\n"
                f"    pass\n"
            )

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(stub_content)
            fragment_paths.append(file_path)

        progress_data['status'] = "Refinement Complete"
        return ModuleDetailResult(spec_path, fragment_paths, entropy)

######################################################################

#################### 檔案: Generate/TestSpawner.py ####################
import os
import json
import time
import re
from typing import List, Dict, Any
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
from OllamaClient import OllamaClient

@dataclass
class TestGenerationResult:
    target_name: str  # 測試目標 (函式名、模組對、或劇本名)
    test_file_path: str
    model_entropy: float
    duration: float
    skipped: bool = False

class TestSpawner:
    def __init__(self, ollama_url: str = "http://localhost:11434"):
        self.client = OllamaClient(ollama_url)

    def _extract_python_code(self, text: str) -> str:
        match = re.search(r"```python\s*(.*?)\s*```", text, re.DOTALL)
        if match: return match.group(1)
        match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
        if match: return match.group(1)
        return text

    def _should_generate_test(self, return_type: str) -> bool:
        """判斷是否需要生成單元測試 (有無回傳值)"""
        if not return_type: return False
        normalized = return_type.lower().strip()
        return normalized not in ['none', 'void', 'noreturn', 'nothing']

    def _generate_single_test(self, spec_data: Dict, func_name: str, tests_dir: str, model_name: str = "gemma3:12b") -> TestGenerationResult:
        start_time = time.time()

        # 1. 獲取函式規格
        target_func_spec = next((f for f in spec_data.get('functions', []) if f['name'] == func_name), None)
        if not target_func_spec:
            return TestGenerationResult(func_name, "", -1.0, 0.0, True)

        # 2. 檢查回傳值
        return_type = target_func_spec.get('return_type', 'None')
        if not self._should_generate_test(return_type):
            print(f"    > Skipping test for {func_name} (Return type: {return_type})")
            return TestGenerationResult(func_name, "", 0.0, 0.0, True)

        print(f"    > Generating Unit Test for {func_name}...")

        # 3. 準備檔案路徑
        test_filename = f"test_{func_name}.py"
        test_file_path = os.path.join(tests_dir, test_filename)

        # 4. 準備 Prompt
        module_name = spec_data.get('module_name', 'unknown_module')

        system_prompt = (
            "You are a QA Engineer Expert in Python unittest. "
            "Write a comprehensive unit test for the specified function. "
            "1. Import `unittest`. "
            "2. Assume the function is available to import (e.g., `from ..{func_name} import {func_name}`). "
            "3. Cover at least 2-3 scenarios (normal case, edge case). "
            "4. Assert the return value matches expectation. "
            "5. Output ONLY the python code."
        )

        func_info = (
            f"Module: {module_name}\n"
            f"Function: {func_name}\n"
            f"Arguments: {target_func_spec.get('args')}\n"
            f"Return Type: {return_type}\n"
            f"Description: {target_func_spec.get('docstring')}"
        )

        user_prompt = (
            f"Target Function Info:\n{func_info}\n\n"
            "Generate the unittest code now:"
        )

        try:
            content_str, entropy = self.client.chat_complete_raw(model_name, system_prompt, user_prompt)
            code_body = self._extract_python_code(content_str)

            # 加入 sys.path hack 讓測試在碎片化狀態下也能跑 (可選，視您如何執行測試而定)
            # 這裡簡單加上標準 import 頭
            if "import unittest" not in code_body:
                code_body = "import unittest\n" + code_body

            with open(test_file_path, 'w', encoding='utf-8') as f:
                f.write(code_body)

            return TestGenerationResult(func_name, test_file_path, entropy, time.time() - start_time, False)

        except Exception as e:
            print(f"[!] Error generating test for {func_name}: {e}")
            return TestGenerationResult(func_name, "", -1.0, 0.0, True)

    def generateUnitTest(self, spec_path: str, target_function_names: List[str], model_name: str= "gemma3:12b") -> List[TestGenerationResult]:
        """
        批次生成單元測試
        """
        if not os.path.exists(spec_path):
            raise FileNotFoundError(f"Spec file not found: {spec_path}")

        with open(spec_path, 'r', encoding='utf-8') as f:
            spec_data = json.load(f)

        module_dir = os.path.dirname(spec_path)
        tests_dir = os.path.join(module_dir, "tests")
        if not os.path.exists(tests_dir):
            os.makedirs(tests_dir)

        results = []
        print(f"[*] Spawning tests for {len(target_function_names)} functions...")

        # 同樣支援並行生成
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_to_name = {
                executor.submit(self._generate_single_test, spec_data, name, tests_dir, model_name): name
                for name in target_function_names
            }

            for future in as_completed(future_to_name):
                res = future.result()
                results.append(res)
                if not res.skipped:
                    print(f"    [Test Created] {res.test_file_path} (Entropy: {res.model_entropy})")

        return results

# --- 新增功能 1: 整合測試 ---
    def generateIntegrationTest(
        self,
        caller_spec_path: str,
        callee_spec_path: str,
        tests_dir: str,
        model_name: str
    ) -> TestGenerationResult:
        """
        生成整合測試：測試 Caller 模組與 Callee 模組之間的互動。
        """
        start_time = time.time()

        # 1. 讀取雙方規格
        if not os.path.exists(caller_spec_path) or not os.path.exists(callee_spec_path):
            return TestGenerationResult("Integration", "", -1.0, 0.0, True)

        with open(caller_spec_path, 'r') as f: caller_data = json.load(f)
        with open(callee_spec_path, 'r') as f: callee_data = json.load(f)

        caller_mod = caller_data['module_name']
        callee_mod = callee_data['module_name']

        filename = f"test_integration_{caller_mod}_v_{callee_mod}.py"
        target_path = os.path.join(tests_dir, filename)

        print(f"[*] Generating Integration Test: {caller_mod} -> {callee_mod}...")

        # 2. 構建 Context：讓 LLM 看到雙方的 Public API
        # 我們只提供簽名 (Signature)，不提供實作，迫使 LLM 關注「介面」
        def extract_public_api(data):
            return [
                f"{f['name']}({', '.join([a['name'] for a in f.get('args', [])])}) -> {f.get('return_type')}"
                for f in data.get('functions', [])
                if f.get('access') == 'public' or f['name'] == '__init__'
            ]

        context_str = (
            f"--- Caller Module: {caller_mod} ---\n"
            f"Description: {caller_data.get('description')}\n"
            f"Public APIs: {json.dumps(extract_public_api(caller_data), indent=2)}\n\n"
            f"--- Callee Module: {callee_mod} ---\n"
            f"Description: {callee_data.get('description')}\n"
            f"Public APIs: {json.dumps(extract_public_api(callee_data), indent=2)}\n"
        )

        # 3. Prompt 設計：防止 Mock 依賴
        system_prompt = (
            "You are a Senior Python QA Engineer specializing in Integration Testing. "
            "Your goal is to verify the contract (handshake) between two specific modules.\n"
            "\n"
            "CRITICAL RULES (To avoid Unit-Test style):\n"
            "1. DO NOT MOCK the Callee Module. You must import and instantiate the REAL class/functions of the Callee.\n"
            "2. You MAY mock external systems (Database, Network, Filesystem) if the Callee uses them.\n"
            "3. Verify that the Caller correctly handles the return values or exceptions from the Callee.\n"
            "4. Structure the test to setup the Callee first, then inject it into the Caller (Dependency Injection pattern).\n"
            "5. Output ONLY Python code."
        )

        user_prompt = (
            f"INTEGRATION CONTEXT:\n{context_str}\n\n"
            f"Task: Write a unittest case where '{caller_mod}' calls '{callee_mod}'. "
            "Ensure data flows correctly between them."
        )

        # 4. 生成與存檔
        try:
            content, entropy = self.client.chat_complete_raw(model_name, system_prompt, user_prompt)
            code = self._extract_python_code(content)

            # 加入必要的 import 修正 (假設專案結構)
            header = "import unittest\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n"
            if "import unittest" not in code:
                code = header + code
            else:
                # 插入 sys.path hack 在 import unittest 之後
                code = code.replace("import unittest", header)

            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(code)

            return TestGenerationResult(f"{caller_mod}->{callee_mod}", target_path, entropy, time.time() - start_time, False)

        except Exception as e:
            print(f"[!] Integration Test Gen Error: {e}")
            return TestGenerationResult("Integration", "", -1.0, 0.0, True)


    # --- 新增功能 2: 模擬系統測試 (End-to-End Mock) ---
    def generateMockSystemTest(
        self,
        architecture_path: str,
        scenario_description: str,
        tests_dir: str,
        model_name: str
    ) -> TestGenerationResult:
        """
        生成模擬系統測試：根據使用者劇本，串接多個模組。
        """
        start_time = time.time()

        # 1. 讀取架構圖 (God View)
        with open(architecture_path, 'r') as f: arch_data = json.load(f)

        filename = f"test_system_scenario_{int(time.time())}.py"
        target_path = os.path.join(tests_dir, filename)

        print(f"[*] Generating System Test for Scenario: {scenario_description[:30]}...")

        # 2. 構建 Context：提供所有模組的簡介，讓 LLM 知道有哪些積木可用
        modules_overview = []
        for m in arch_data.get('modules', []):
            modules_overview.append(f"- Module '{m['name']}': {m.get('description')}")
            # 若有 API summary 也可加入，但保持簡短以免 context 爆炸

        context_str = "\n".join(modules_overview)

        # 3. Prompt 設計：強調狀態流轉 (State Propagation)
        system_prompt = (
            "You are a System Architect writing an End-to-End System Test. "
            "Your goal is to simulate a complete user workflow using multiple internal modules.\n"
            "\n"
            "CRITICAL RULES:\n"
            "1. NO ISOLATION: Do not test functions in vacuum. Connect them.\n"
            "2. STATE PROPAGATION: The output of Step 1 MUST be passed as input to Step 2. (e.g., `user = auth.login(); profile = db.get_profile(user.id)`)\n"
            "3. MOCK BOUNDARIES ONLY: Use `unittest.mock` ONLY for IO (Network, Disk, API). Do NOT mock internal logic classes.\n"
            "4. Write a script that executes the scenario from start to finish.\n"
            "5. Output ONLY Python code."
        )

        user_prompt = (
            f"SYSTEM ARCHITECTURE:\n{context_str}\n\n"
            f"TARGET SCENARIO: \"{scenario_description}\"\n\n"
            "Write a python script (using unittest) to verify this scenario."
        )

        # 4. 生成與存檔
        try:
            content, entropy = self.client.chat_complete_raw(model_name, system_prompt, user_prompt)
            code = self._extract_python_code(content)

            header = "import unittest\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n"
            if "import unittest" not in code:
                code = header + code
            else:
                code = code.replace("import unittest", header)

            with open(target_path, 'w', encoding='utf-8') as f:
                f.write(code)

            return TestGenerationResult("SystemScenario", target_path, entropy, time.time() - start_time, False)

        except Exception as e:
            print(f"[!] System Test Gen Error: {e}")
            return TestGenerationResult("SystemScenario", "", -1.0, 0.0, True)

######################################################################

#################### 檔案: Dynamic/ChaosExecuter.py ####################
import os
import json
import time
import random
import importlib.util
import unittest
import sys
from typing import Dict, Any, List
from dataclasses import dataclass

@dataclass
class ChaosResult:
    function_name: str
    injection_type: str
    survival_rate: float
    error_log: List[str]

class ChaosExecuter:
    def __init__(self, workspace_dir: str = "./vibe_workspace"):
        self.workspace_dir = os.path.abspath(workspace_dir)

    def _load_module_from_path(self, file_path: str, module_name: str):
        """動態載入模組"""
        spec = importlib.util.spec_from_file_location(module_name, file_path)
        if spec and spec.loader:
            module = importlib.util.module_from_spec(spec)
            sys.modules[module_name] = module # 註冊到 sys.modules 以便被測試程式 import
            spec.loader.exec_module(module)
            return module
        return None

    def _create_poisoned_wrapper(self, original_func, injection_config: Dict):
        """
        [核心] 製造有毒的函式包裝器
        """
        def wrapper(*args, **kwargs):
            inj_type = injection_config.get('type')

            # 1. 延遲注入 (Latency)
            if inj_type == 'Latency':
                delay = float(injection_config.get('value', 1.0))
                # print(f"  [Chaos] Injecting Latency: {delay}s")
                time.sleep(delay)
                return original_func(*args, **kwargs)

            # 2. 異常注入 (Exception)
            elif inj_type == 'Exception':
                error_msg = injection_config.get('details', 'Chaos Injection Error')
                # print(f"  [Chaos] Injecting Exception: {error_msg}")
                # 模擬常見錯誤
                if "Timeout" in error_msg: raise TimeoutError(error_msg)
                if "Value" in error_msg: raise ValueError(error_msg)
                if "Connection" in error_msg: raise ConnectionError(error_msg)
                raise RuntimeError(f"Chaos: {error_msg}")

            # 3. 數據汙染 (Data Corruption)
            elif inj_type == 'DataCorruption':
                # 簡單將第一個字串參數變空，或數字變負數
                new_args = list(args)
                if new_args:
                    if isinstance(new_args[0], str): new_args[0] = ""
                    elif isinstance(new_args[0], (int, float)): new_args[0] = -99999
                # print(f"  [Chaos] Corrupting Data: {args} -> {new_args}")
                return original_func(*tuple(new_args), **kwargs)

            # 預設：不攻擊，直接執行
            return original_func(*args, **kwargs)

        return wrapper

    def produceChaos(self, module_name: str, test_rounds: int = 5) -> str:
        """
        執行混沌測試
        Returns: 報告 JSON 檔案路徑
        """
        module_dir = os.path.join(self.workspace_dir, module_name)
        plan_path = os.path.join(module_dir, "chaos_plan.json")
        tests_dir = os.path.join(module_dir, "tests")

        if not os.path.exists(plan_path):
            return f"Error: Plan not found at {plan_path}"

        print(f"[*] [ChaosExecuter] Unleashing chaos on {module_name}...")

        with open(plan_path, 'r') as f:
            plan = json.load(f)

        results = []

        # 遍歷計畫中的每個實驗
        for exp in plan.get('experiments', []):
            target_func_name = exp['target_function']
            injections = exp.get('injections', [])

            # 1. 尋找對應的實作檔案與測試檔案
            impl_file = "__init_logic__.py" if target_func_name == "__init__" else f"{target_func_name}.py"
            impl_path = os.path.join(module_dir, impl_file)
            test_path = os.path.join(tests_dir, f"test_{target_func_name}.py")

            if not os.path.exists(test_path):
                print(f"  [Skip] No unit test found for {target_func_name}. Cannot drive execution.")
                continue

            # 2. 載入目標模組 (為了 Patch)
            # 注意：這裡我們假設每個函式是獨立檔案，這讓 Patch 變得容易
            target_mod = self._load_module_from_path(impl_path, f"{module_name}.{target_func_name}")
            if not target_mod or not hasattr(target_mod, target_func_name):
                print(f"  [Skip] Implementation not found for {target_func_name}")
                continue

            # 保存原始函式
            original_func = getattr(target_mod, target_func_name)

            # 3. 針對每種注入類型進行測試
            for inj in injections:
                inj_type = inj['type']
                success_count = 0
                error_logs = []

                print(f"  > Target: {target_func_name} | Attack: {inj_type} | Rounds: {test_rounds}")

                # 套用「有毒」的包裝器
                poisoned_func = self._create_poisoned_wrapper(original_func, inj)
                setattr(target_mod, target_func_name, poisoned_func)

                # 4. 反覆執行測試
                for i in range(test_rounds):
                    # 使用 unittest TestLoader 來載入並執行該測試檔案
                    loader = unittest.TestLoader()
                    try:
                        # 動態載入測試模組
                        test_spec = importlib.util.spec_from_file_location("temp_test", test_path)
                        test_mod = importlib.util.module_from_spec(test_spec)
                        test_spec.loader.exec_module(test_mod)

                        suite = loader.loadTestsFromModule(test_mod)
                        runner = unittest.TextTestRunner(stream=open(os.devnull, 'w'), verbosity=0) # 靜音輸出
                        result = runner.run(suite)

                        if result.wasSuccessful():
                            success_count += 1
                        else:
                            # 測試失敗 (代表程式碼沒處理好這個異常)
                            err_msg = f"Round {i+1}: Test Failed."
                            if result.errors: err_msg += f" Err: {result.errors[0][1].splitlines()[-1]}"
                            if result.failures: err_msg += f" Fail: {result.failures[0][1].splitlines()[-1]}"
                            error_logs.append(err_msg)

                    except Exception as e:
                        error_logs.append(f"Round {i+1}: Crashed ({str(e)})")

                # 5. 復原原始函式 (清理戰場)
                setattr(target_mod, target_func_name, original_func)

                # 記錄結果
                survival_rate = round(success_count / test_rounds, 2)
                results.append({
                    "function": target_func_name,
                    "injection": inj_type,
                    "survival_rate": survival_rate,
                    "status": "RESILIENT" if survival_rate >= 0.8 else "FRAGILE",
                    "details": inj,
                    "logs": error_logs[:3] # 只留前幾條錯誤以免 JSON 太大
                })

                print(f"    -> Survival Rate: {survival_rate*100}%")

        # 6. 輸出報告
        report_path = os.path.join(module_dir, "chaos_report.json")
        final_output = {
            "timestamp": time.time(),
            "module": module_name,
            "results": results
        }
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_output, f, indent=4)

        return report_path

######################################################################

#################### 檔案: Dynamic/RuntimeAnalyst.py ####################
import os
import json
from typing import Dict, List, Optional, Any, Tuple
import sys
sys.path.append("Generate")
from OllamaClient import OllamaClient

class RuntimeAnalyst:
    def __init__(self, ollama_url: str = "http://localhost:11434"):
        self.client = OllamaClient(ollama_url)

    def analyzeSnapshot(
        self,
        screenshot_path: str,
        func_description: str,
        user_report: str,
        vision_model: str = "gemma3:4b"
    ) -> Tuple[str, float]: # [修正] 回傳 Tuple
        """
        視覺除錯分析
        """
        if not screenshot_path or not os.path.exists(screenshot_path):
            return "Analysis Failed: Screenshot not found.", 0.0

        print(f"[*] [RuntimeAnalyst] Analyzing GUI snapshot with {vision_model}...")

        # [修正] Prompt：強制簡潔正式
        system_prompt = (
            "You are a strict UI Verification Engine. "
            "Analyze the GUI screenshot based on the User Report. "
            "\n\n"
            "CRITICAL FORMATTING RULES:\n"
            "1. Output ONLY the analysis list. DO NOT generate document headers, dates, IDs, or introductory text.\n"
            "2. For each distinct issue or element, use the following EXACT format block:\n"
            "\n"
            "### ELEMENT: <Name of the UI component (e.g., 'Progress Bar', 'Save Button')>\n"
            "1. VISUAL_OBSERVATION: <What you see pixels-wise>\n"
            "2. SPEC_CHECK: <Pass/Fail>\n"
            "3. ISSUE_VERIFICATION: <Confirmed/Denied based on user report>\n"
            "4. FIX_SUGGESTION: <Specific fix>\n"
            "\n"
            "3. If multiple issues exist, repeat the block for each one."
        )

        user_prompt = (
            f"FUNCTION_GOAL: {func_description}\n"
            f"USER_REPORT: {user_report}\n"
            "Analyze the attached screenshot."
        )

        # 呼叫更新後的 Client (會自動處理 Base64)
        content, entropy = self.client.chat_complete_raw(
            model=vision_model,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            images=[screenshot_path]
        )
        return content, entropy

    def analyzeBottleNeck(
        self,
        func_name: str,
        perf_data: Dict[str, Any],
        io_data: Dict[str, Any],
        coverage_data: Dict[str, Any],
        calls_data: List[Dict[str, Any]],
        logic_model: str = "gemma3:12b"
    ) -> Tuple[str, float]: # [修正] 回傳 Tuple
        """
        效能瓶頸分析
        """
        print(f"[*] [RuntimeAnalyst] Analyzing bottlenecks for '{func_name}' with {logic_model}...")

        # A. 效能數據 (增加防禦性檢查，避免 Zero Call Count 誤判)
        metric = perf_data.get(func_name)
        if metric is None:
            # 如果找不到該函式的數據，直接回傳錯誤，不要讓 LLM 瞎掰
            return f"Error: No performance data found for function '{func_name}'. Check function name spelling.", 0.0

        avg_time = metric.get("avg_time_ms", 0)
        total_time = metric.get("total_time_ms", 0)
        calls = metric.get("total_calls", 0)
        mem_peak = metric.get("memory_peak_bytes", 0)

        # B. IO 數據
        io_metric = io_data.get(func_name, {"read": 0, "write": 0})

        # C. 覆蓋率分析
        lines_info = coverage_data.get(func_name, {})
        hotspots = []
        dead_code = []
        # 簡單過濾，只取前 3 個熱點以節省 Context
        sorted_lines = sorted(lines_info.items(), key=lambda x: x[1]['hits'], reverse=True)
        for line_key, info in sorted_lines:
            hits = info.get("hits", 0)
            code = info.get("source", "").strip()
            if hits == 0:
                dead_code.append(f"{line_key}: {code}")
            elif hits > 50: # 門檻值
                hotspots.append(f"{line_key} (Hits={hits}): {code}")

        # D. 外部呼叫
        outgoing_calls = [c for c in calls_data if c['caller'] == func_name]

        # 2. 彙整 Context 字串
        analysis_context = (
            f"TARGET: {func_name}\n"
            f"METRICS: Time={total_time}ms (Avg {avg_time}ms), Calls={calls}, MemPeak={mem_peak}B\n"
            f"IO: R={io_metric.get('read')}B, W={io_metric.get('write')}B\n"
            f"HOTSPOTS (Top 5): {json.dumps(hotspots[:5], ensure_ascii=False)}\n"
            f"DEAD_CODE (Top 5): {json.dumps(dead_code[:5], ensure_ascii=False)}\n"
            f"OUTGOING_CALLS: {len(outgoing_calls)}\n"
        )

        # [修正] Prompt：強制簡潔正式
        system_prompt = (
            "You are a Kernel Profiling Expert. "
            "Output a concise performance diagnosis. "
            "NO conversational filler. "
            "Format strictly as:\n"
            "1. BOTTLENECK_ID: <Loop/IO/Memory/Logic>\n"
            "2. SEVERITY: <High/Medium/Low>\n"
            "3. ROOT_CAUSE: <Technical explanation based on metrics>\n"
            "4. OPTIMIZATION: <Specific Code/Architecture change>"
        )

        user_prompt = (
            f"DATA:\n{analysis_context}\n\n"
            "Diagnose performance."
        )

        content, entropy = self.client.chat_complete_raw(logic_model, system_prompt, user_prompt)
        return content, entropy

######################################################################

#################### 檔案: Dynamic/MetricCollector.py ####################
import sys
import time
import tracemalloc
import builtins
import os
import tkinter
import importlib
from typing import Dict, List, Any
from dataclasses import dataclass
from collections import defaultdict # 記得 import 這個
import json

try:
    from PIL import ImageGrab
    HAS_PIL = True
except ImportError:
    HAS_PIL = False

# --- 新增：DPI 感知 (保持不變) ---
def _set_dpi_awareness():
    if sys.platform == "win32":
        try:
            import ctypes
            ctypes.windll.shcore.SetProcessDpiAwareness(1)
        except:
            try:
                import ctypes
                ctypes.windll.user32.SetProcessDPIAware()
            except: pass

@dataclass
class FunctionMetric:
    func_name: str
    call_count: int = 0
    total_time_ms: float = 0.0
    memory_peak_bytes: int = 0
    io_read_bytes: int = 0
    io_write_bytes: int = 0

@dataclass
class CallRecord:
    caller: str
    callee: str
    elapsed_time_sec: float

class FileProxy:
    def __init__(self, real_file, collector):
        self._real_file = real_file
        self._collector = collector
    def read(self, size=-1):
        data = self._real_file.read(size)
        if data: self._collector._record_io(read=len(str(data)))
        return data
    def write(self, data):
        if data: self._collector._record_io(write=len(str(data)))
        return self._real_file.write(data)
    def __getattr__(self, name): return getattr(self._real_file, name)
    def __enter__(self): self._real_file.__enter__(); return self
    def __exit__(self, exc_type, exc_val, exc_tb): return self._real_file.__exit__(exc_type, exc_val, exc_tb)

class MetricCollector:
    def __init__(self):
        self._reset_state()
        self._orig_tk_methods = {}
        self._orig_open = None

    def _reset_state(self):
        self.metrics = {}
        self.call_history = []
        self.screenshots = []
        self._current_function_stack = []
        self._start_times = {}
        self._mem_snapshots = {}
        self._exec_start_time = 0.0
        self._last_snap_time = 0.0
        self._screenshot_interval = 1.0

        # [修正] 初始化原始碼儲存列表與計數器
        self._source_code_lines: List[str] = []
        self._line_hit_counts: Dict[str, Dict[int, int]] = defaultdict(lambda: defaultdict(int))

    def _get_metric(self, name):
        if name not in self.metrics: self.metrics[name] = FunctionMetric(name)
        return self.metrics[name]

    def _record_io(self, read=0, write=0):
        if self._current_function_stack:
            m = self._get_metric(self._current_function_stack[-1])
            m.io_read_bytes += read
            m.io_write_bytes += write

    def _tracer(self, frame, event, arg):
        code = frame.f_code
        fname = code.co_name

        # 排除自身
        if "MetricCollector" in str(code.co_filename) or fname.startswith("_"):
            return self._tracer

        now = time.time()

        # [功能] 覆蓋率計算
        if event == 'line':
            line_no = frame.f_lineno
            self._line_hit_counts[fname][line_no] += 1
            return self._tracer

        if event == 'call':
            caller = self._current_function_stack[-1] if self._current_function_stack else "root"
            self.call_history.append(CallRecord(caller, fname, round(now - self._exec_start_time, 6)))
            self._current_function_stack.append(fname)
            self._start_times[fname] = now
            self._mem_snapshots[fname] = tracemalloc.get_traced_memory()[0]
            self._get_metric(fname).call_count += 1
            return self._tracer # 必須回傳 tracer 以啟用 line 事件

        elif event == 'return':
            if self._current_function_stack and self._current_function_stack[-1] == fname:
                self._current_function_stack.pop()
                dur = (now - self._start_times.get(fname, now)) * 1000
                m = self._get_metric(fname)
                m.total_time_ms += dur
                peak = max(0, tracemalloc.get_traced_memory()[0] - self._mem_snapshots.get(fname, 0))
                if peak > m.memory_peak_bytes: m.memory_peak_bytes = peak
            return self._tracer

        return self._tracer

    def _snapshot(self, root):
        if not HAS_PIL: return
        now = time.time()
        if now - self._last_snap_time < self._screenshot_interval: return
        try:
            if not root.winfo_exists(): return
            root.update_idletasks() # 關鍵：同步座標
            x, y = root.winfo_rootx(), root.winfo_rooty()
            w, h = root.winfo_width(), root.winfo_height()

            # Linux 邊框修正邏輯 (視需要啟用)
            # if sys.platform == "linux": y -= 30

            if w > 10 and h > 10:
                fname = os.path.abspath(f"gui_snap_{int(now*1000)}.png")
                # 如果是 Linux 且有安裝 import，可考慮用 os.system(f"import -window {root.winfo_id()} ...")
                # 這裡預設使用 PIL
                import PIL.ImageGrab
                PIL.ImageGrab.grab(bbox=(x, y, x+w, y+h)).save(fname)
                if os.path.exists(fname):
                    self.screenshots.append(fname)
                    self._last_snap_time = now
        except: pass

    def _patch_tkinter(self):
        if not isinstance(tkinter.Tk, type): importlib.reload(tkinter)
        tk = tkinter.Tk
        self._orig_tk_methods = {'update': tk.update, 'mainloop': tk.mainloop}

        def hooked_update(self_tk):
            self._orig_tk_methods['update'](self_tk)
            self._snapshot(self_tk)

        def hooked_mainloop(self_tk, *args, **kwargs):
            def scheduled_snapshot():
                if self_tk.winfo_exists():
                    self._snapshot(self_tk)
                    self_tk.after(1000, scheduled_snapshot)
            scheduled_snapshot()
            self._orig_tk_methods['mainloop'](self_tk, *args, **kwargs)

        tk.update = hooked_update
        tk.mainloop = hooked_mainloop

    def _unpatch_tkinter(self):
        tk = tkinter.Tk
        if self._orig_tk_methods:
            tk.update = self._orig_tk_methods['update']
            tk.mainloop = self._orig_tk_methods['mainloop']
        self._orig_tk_methods = {}

    def _hook_open(self, orig_open):
        def hooked(file, mode='r', *args, **kwargs):
            return FileProxy(orig_open(file, mode, *args, **kwargs), self)
        return hooked

    def execute_code(self, code_str: str):
        _set_dpi_awareness()
        self._reset_state()

        # --- [修正] 關鍵的一行：填充原始碼列表 ---
        # 處理 user_code 開頭可能的空白行，確保行號對齊
        self._source_code_lines = code_str.splitlines()

        tracemalloc.start()
        self._orig_open = builtins.open
        builtins.open = self._hook_open(self._orig_open)
        self._patch_tkinter()
        self._exec_start_time = time.time()
        sys.settrace(self._tracer)

        global_scope = {"__name__": "__main__", "tk": tkinter, "tkinter": tkinter}

        try:
            print("[MetricCollector] Executing user code...")
            exec(code_str, global_scope)
        except Exception as e:
            print(f"[MetricCollector] Runtime Error: {e}")
        finally:
            sys.settrace(None)
            if self._orig_open: builtins.open = self._orig_open
            self._unpatch_tkinter()
            tracemalloc.stop()
            print("[MetricCollector] Analysis finished.")

    # --- APIs ---
    def getBenchmarkData(self):
        res = {}
        for n, m in self.metrics.items():
            avg = m.total_time_ms / m.call_count if m.call_count else 0
            res[n] = {"calls": m.call_count, "time_ms": round(m.total_time_ms, 4), "avg_ms": round(avg, 4), "mem_peak": m.memory_peak_bytes}
        return res
    def getCallHistory(self): return [vars(c) for c in self.call_history]
    def getIOHistory(self): return {n: {"r": m.io_read_bytes, "w": m.io_write_bytes} for n, m in self.metrics.items() if m.io_read_bytes or m.io_write_bytes}
    def getGUIScreenshot(self): return self.screenshots

    # --- [功能] 獲取覆蓋率報告 ---
    def getCodeCoverage(self) -> Dict[str, Any]:
        coverage_report = {}
        for func_name, line_hits in self._line_hit_counts.items():
            func_report = {}
            for line_no, count in line_hits.items():
                code_content = "<unknown>"
                # 修正索引：行號從 1 開始，List 索引從 0 開始
                if 0 <= line_no - 1 < len(self._source_code_lines):
                    code_content = self._source_code_lines[line_no - 1].strip()

                func_report[f"line_{line_no}"] = {
                    "source": code_content,
                    "hits": count,
                    "type": "loop_hotspot" if count > 1 else "visited"
                }
            coverage_report[func_name] = func_report
        return coverage_report

    # --- [功能] 標準化輸出 ---
    def outputMetricResult(self, target_funcs: List[str] = None) -> str:
        """
        將收集到的數據打包成 JSON。
        Args:
            target_funcs: 若指定，則只輸出這些函式的數據 (例如 ["complex_logic"])。
                          若為 None 或空，則輸出全部。
        """

        # 輔助過濾函式
        def filter_dict(source_dict):
            if not target_funcs: return source_dict
            return {k: v for k, v in source_dict.items() if k in target_funcs}

        # 針對 Call Graph 的特殊過濾 (只保留 caller 或 callee 在目標清單中的紀錄)
        filtered_calls = self.getCallHistory()
        if target_funcs:
            filtered_calls = [
                c for c in filtered_calls
                if c['caller'] in target_funcs or c['callee'] in target_funcs
            ]

        final_report = {
            "meta": {
                "timestamp": time.time(),
                "platform": sys.platform,
                "filter_applied": target_funcs if target_funcs else "ALL"
            },
            "performance": filter_dict(self.getBenchmarkData()),
            "io_activity": filter_dict(self.getIOHistory()),
            "code_coverage": filter_dict(self.getCodeCoverage()),
            "call_graph": filtered_calls,
            # Screenshot 是全域的，無法依函式過濾，故保留
            "gui_screenshots": self.getGUIScreenshot(),
        }

        return json.dumps(final_report, indent=2, ensure_ascii=False)

######################################################################

#################### 檔案: GUI/IntelligencePanel.py ####################
import tkinter as tk
from tkinter import ttk, scrolledtext

class IntelligencePanel:
    def __init__(self, parent, mediator):
        self.mediator = mediator
        # 獲取由 MainWindow 傳遞的顏色配置
        colors = getattr(mediator, 'colors', {'bg': '#333', 'fg': '#eee', 'console_bg': '#1e1f22'})

        self.frame = ttk.LabelFrame(parent, text="Vibe Intelligence")

        # Log 區域 (暗色配置)
        self.log_area = scrolledtext.ScrolledText(
            self.frame,
            height=20,
            bg=colors['console_bg'],
            fg="#00ff00", # Hacker Green
            font=("Consolas", 9),
            insertbackground="white", # 游標顏色
            selectbackground="#214283"
        )
        self.log_area.pack(fill=tk.BOTH, expand=True)

    def log(self, msg):
        """
        [修復] 這是之前遺失的關鍵方法。
        負責將訊息寫入 ScrolledText 元件。
        """
        # 使用 tk.END 插入到最後
        self.log_area.insert(tk.END, f"> {msg}\n")
        # 自動捲動到底部
        self.log_area.see(tk.END)

    def on_diagnose(self):
        """
        執行診斷邏輯
        需要從 WorkSpace 獲取當前程式碼 -> 呼叫 Backend -> 顯示結果
        """
        # 1. 跨元件獲取程式碼 (透過 Mediator)
        # MainWindow -> WorkSpace -> CodeEditor
        try:
            code = self.mediator.workspace.code_editor.get("1.0", tk.END).strip()
            # 簡單假設目前選中的是目標函式 (這裡可以優化為從 ProjectExplorer 獲取名稱)
            # 暫時用 "unknown_func" 或讓使用者輸入，這裡先寫死測試用
            func_name = "complex_logic"
        except Exception:
            code = ""
            func_name = "unknown"

        if not code:
            self.log("[Warn] Editor is empty. Nothing to diagnose.")
            return

        def task():
            self.mediator.log(f"Running Diagnostics on {func_name}...")

            # 呼叫 MetaCoder 的動態分析
            # 注意：這裡假設代碼可以直接執行 (self-contained)
            report = self.mediator.meta.run_dynamic_analysis(code, func_name)

            # 格式化輸出報告
            output = f"\n=== DIAGNOSTIC REPORT: {func_name} ===\n"
            output += f"Entropy (Logic): {report['entropies'][0]}\n"
            output += f"Entropy (Vision): {report['entropies'][1]}\n\n"

            output += "--- Logic Bottlenecks ---\n"
            output += report['logic_report'] + "\n"

            if report['vision_report']:
                output += "\n--- Visual Analysis ---\n"
                output += report['vision_report'] + "\n"

            self.mediator.log(output)

        # 透過 Mediator 執行非同步任務
        self.mediator.run_async(task)

######################################################################

#################### 檔案: GUI/MainWindow.py ####################
import tkinter as tk
from tkinter import ttk, messagebox
import threading
import os
import queue
from ProjectExplorer import ProjectExplorer
from WorkSpace import WorkSpace
from IntelligencePanel import IntelligencePanel
from ControlPanel import ControlPanel

class MainWindow:
    def __init__(self, root, meta_coder):
        self.root = root
        self.meta = meta_coder

        # [UI Config]
        self.root.title("Vibe-Coder IDE") # 已移除 (Dark Mode)
        self.root.geometry("1400x900")

        # [Task Management]
        self._current_cancel_flag = threading.Event()
        self.task_queue = queue.Queue()
        self._is_worker_running = False
        self._queue_loop_running = False # 防止重複啟動 Loop

        # [Initialization]
        self._apply_dark_theme()
        self._init_layout()
        self._init_menu()

        # 啟動任務隊列監聽 (只啟動一次)
        self._start_queue_loop()

    def _apply_dark_theme(self):
        style = ttk.Style()
        style.theme_use('clam')

        bg_dark = "#2b2b2b"
        bg_lighter = "#3c3f41"
        fg_text = "#a9b7c6"
        accent = "#4a88c7"
        sel_bg = "#214283"

        style.configure(".", background=bg_dark, foreground=fg_text, borderwidth=0)
        style.configure("TFrame", background=bg_dark)
        style.configure("TLabelframe", background=bg_dark, foreground=fg_text, bordercolor=bg_lighter)
        style.configure("TLabelframe.Label", background=bg_dark, foreground=fg_text)
        style.configure("TButton", background=bg_lighter, foreground=fg_text, borderwidth=1, focuscolor=accent)
        style.map("TButton", background=[("active", "#4c5052"), ("pressed", "#5c6062")])

        style.configure("Treeview", background=bg_lighter, foreground=fg_text, fieldbackground=bg_lighter, borderwidth=0)
        style.map("Treeview", background=[("selected", sel_bg)])

        style.configure("TNotebook", background=bg_dark)
        style.configure("TNotebook.Tab", background=bg_lighter, foreground=fg_text, padding=[10, 2])
        style.map("TNotebook.Tab", background=[("selected", bg_dark)], foreground=[("selected", "#ffffff")])

        style.configure("TPanedwindow", background=bg_dark)
        style.configure("Sash", sashthickness=2, background="#555555")

        self.root.configure(bg=bg_dark)
        self.colors = {"bg": bg_dark, "fg": fg_text, "editor_bg": "#1e1f22", "console_bg": "#1e1f22"}

    def _init_layout(self):
        # 使用 PanedWindow 進行佈局
        self.main_pane = tk.PanedWindow(self.root, orient=tk.VERTICAL, sashrelief=tk.FLAT, bg=self.colors['bg'])
        self.main_pane.pack(fill=tk.BOTH, expand=True)

        self.top_pane = tk.PanedWindow(self.main_pane, orient=tk.HORIZONTAL, sashrelief=tk.FLAT, bg=self.colors['bg'])
        self.main_pane.add(self.top_pane, height=700)

        # 左側導航
        self.nav = ProjectExplorer(self.top_pane, self)
        self.top_pane.add(self.nav.frame, width=250)

        # 中間工作區
        self.workspace = WorkSpace(self.top_pane, self)
        self.top_pane.add(self.workspace.frame, width=800)

        # 右側情報區
        self.intelligence = IntelligencePanel(self.top_pane, self)
        self.top_pane.add(self.intelligence.frame, width=350)

        # 下方控制區
        self.controls = ControlPanel(self.main_pane, self)
        self.main_pane.add(self.controls.frame)

    def _init_menu(self):
        menubar = tk.Menu(self.root, bg="#3c3f41", fg="#a9b7c6", activebackground="#4b6eaf", activeforeground="white")

        file_menu = tk.Menu(menubar, tearoff=0, bg="#3c3f41", fg="#a9b7c6")
        file_menu.add_command(label="Open Workspace...", command=self.on_open_workspace)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit)
        menubar.add_cascade(label="File", menu=file_menu)

        edit_menu = tk.Menu(menubar, tearoff=0, bg="#3c3f41", fg="#a9b7c6")
        edit_menu.add_command(label="Undo", command=lambda: self.log("Undo not implemented"))
        menubar.add_cascade(label="Edit", menu=edit_menu)

        settings_menu = tk.Menu(menubar, tearoff=0, bg="#3c3f41", fg="#a9b7c6")
        settings_menu.add_command(label="Model Selection...", command=self.on_model_settings)
        menubar.add_cascade(label="Settings", menu=settings_menu)

        self.root.config(menu=menubar)

    # --- Task Queue System ---
    def _start_queue_loop(self):
        if self._queue_loop_running: return
        self._queue_loop_running = True
        self._check_queue_loop()

    def _check_queue_loop(self):
        # 簡單的 Keep-alive，實際執行由 Worker Thread 負責
        self.root.after(1000, self._check_queue_loop)

    def run_async(self, task_func, success_callback=None, error_callback=None, cancel_callback=None):
        # [Fix 3] 任務進來時，確保服務啟動
        # 注意：這可能會卡住 UI 一兩秒，最好放在 Worker 裡面做
        # 但為了簡單，我們在這裡呼叫，反正 OllamaManager 有 check running

        task_item = {
            'func': task_func,
            'success': success_callback,
            'error': error_callback,
            'cancel': cancel_callback
        }
        self.task_queue.put(task_item)

        if not self._is_worker_running:
            self._start_worker_thread()

    def _start_worker_thread(self):
        self._is_worker_running = True
        self.controls.set_running_state(True)

        def worker():

            # [Fix 3] Worker 啟動時確保 Ollama 活著
            self.log("[System] Ensuring Ollama service is running...")
            self.meta.ensure_ollama_started()

            while True:
                try:
                    # 阻塞式獲取，直到有任務或 timeout (讓出檢查 stop flag)
                    task_item = self.task_queue.get(timeout=1)
                except queue.Empty:
                    # 隊列空了，結束 worker
                    if self.task_queue.empty():
                        break
                    continue

                if self._current_cancel_flag.is_set():
                    # 清空剩餘任務
                    with self.task_queue.mutex:
                        self.task_queue.queue.clear()
                    self.log("[System] Remaining tasks cancelled.")
                    break

                try:
                    task_item['func']()

                    if self._current_cancel_flag.is_set():
                        if task_item['cancel']: self.root.after(0, task_item['cancel'])
                    else:
                        if task_item['success']: self.root.after(0, task_item['success'])
                        self.set_status("Ready")

                except Exception as e:
                    self.log(f"[Error] {e}")
                    if task_item['error']: self.root.after(0, lambda: task_item['error'](e))
                finally:
                    self.task_queue.task_done()

            self._is_worker_running = False
            self._current_cancel_flag.clear()
            self.root.after(0, lambda: self.controls.set_running_state(False))

        threading.Thread(target=worker, daemon=True).start()

    def stop_current_task(self):
        if self._is_worker_running:
            self.log("[System] NUCLEAR STOP DETECTED. Killing Ollama...")

            # [Fix 3] 核選項：先殺服務
            self.meta.kill_ollama()

            # 再設定旗標清空隊列
            self._current_cancel_flag.set()

    # --- Actions ---
    def on_open_workspace(self):
        from tkinter import filedialog
        dir_path = filedialog.askdirectory()
        if dir_path:
            self.log(f"Switching workspace to: {dir_path}")
            self.meta.set_workspace(dir_path)
            self.nav.set_workspace(dir_path)

            # 清空 UI
            self.workspace.clear_all_editors()
            self.workspace.canvas.delete("all")

            self.root.title(f"Vibe-Coder IDE - {os.path.basename(dir_path)}")

    def on_model_settings(self):
        win = tk.Toplevel(self.root)
        win.title("Model Configuration")
        win.geometry("400x300")
        win.configure(bg=self.colors['bg'])

        row = 0
        entries = {}
        for role, current_model in self.meta.model_config.items():
            tk.Label(win, text=f"{role.capitalize()} Model:", bg=self.colors['bg'], fg=self.colors['fg']).grid(row=row, column=0, padx=10, pady=10, sticky="w")
            ent = tk.Entry(win, bg="#555", fg="white")
            ent.insert(0, current_model)
            ent.grid(row=row, column=1, padx=10, pady=10, sticky="ew")
            entries[role] = ent
            row += 1

        def save():
            for role, ent in entries.items():
                self.meta.update_model_config(role, ent.get())
            win.destroy()
            self.log("Model settings updated.")

        tk.Button(win, text="Save", command=save, bg="#4a88c7", fg="white").grid(row=row, column=0, columnspan=2, pady=20)

    # --- Helpers ---
    def log(self, msg): self.intelligence.log(msg)
    def set_status(self, msg): self.controls.set_status(msg)

######################################################################

#################### 檔案: GUI/WorkSpace.py ####################
import tkinter as tk
from tkinter import ttk, scrolledtext
import math
import random
import os

class WorkSpace:
    def __init__(self, parent, mediator):
        self.mediator = mediator
        self.colors = mediator.colors

        self.frame = ttk.Frame(parent)

        self.notebook = ttk.Notebook(self.frame)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        self.notebook.bind("<<NotebookTabChanged>>", self.on_tab_change)

        # --- Tab 1: Code Editor (Multi-tab) ---
        self.editor_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.editor_frame, text="Code Editor")

        # 編輯器頂部工具列
        self.editor_toolbar = tk.Frame(self.editor_frame, bg=self.colors['bg'], height=24)
        self.editor_toolbar.pack(side=tk.TOP, fill=tk.X)

        # 關閉按鈕
        self.btn_close_tab = tk.Button(
            self.editor_toolbar, text="×", font=("Arial", 12, "bold"),
            bg=self.colors['bg'], fg="#ff5555", bd=0,
            activebackground="#ff5555", activeforeground="white",
            command=self.close_current_file, cursor="hand2", width=3
        )
        self.btn_close_tab.pack(side=tk.RIGHT, padx=2)

        self.lbl_current_file = tk.Label(self.editor_toolbar, text="", bg=self.colors['bg'], fg="#888", font=("Consolas", 9))
        self.lbl_current_file.pack(side=tk.LEFT, padx=5)

        # 內部分頁
        self.editor_notebook = ttk.Notebook(self.editor_frame)
        self.editor_notebook.pack(fill=tk.BOTH, expand=True)
        self.editor_notebook.bind("<<NotebookTabChanged>>", self.on_editor_tab_change)

        self.opened_files_map = {} # frame -> file_path
        self.path_to_frame = {}    # file_path -> frame

        # --- Tab 2: Dependency Graph ---
        self.canvas = tk.Canvas(self.notebook, bg=self.colors['editor_bg'], highlightthickness=0)
        self.notebook.add(self.canvas, text="Dependency Graph")

        self.canvas.bind("<Button-1>", self.on_canvas_click)
        self._hit_areas = []
        self.selected_node = None
        self._init_graph_menu()

        # --- Tab 2: Dependency Graph ---
        self.graph_frame = ttk.Frame(self.notebook) # 包裝 Canvas 和控制列
        self.notebook.add(self.graph_frame, text="Dependency Graph")

        # 控制列
        self.graph_toolbar = tk.Frame(self.graph_frame, bg=self.colors['bg'])
        self.graph_toolbar.pack(fill=tk.X, side=tk.TOP)

        self.view_mode = tk.StringVar(value="function")
        ttk.Radiobutton(self.graph_toolbar, text="Function View", value="function", variable=self.view_mode, command=self.draw_dependency_graph).pack(side=tk.LEFT, padx=5)
        ttk.Radiobutton(self.graph_toolbar, text="Module View", value="module", variable=self.view_mode, command=self.draw_dependency_graph).pack(side=tk.LEFT, padx=5)

        self.canvas = tk.Canvas(self.graph_frame, bg=self.colors['editor_bg'], highlightthickness=0)
        self.canvas.pack(fill=tk.BOTH, expand=True)

    def _init_graph_menu(self):
        self.graph_menu = tk.Menu(self.canvas, tearoff=0)
        self.graph_menu.add_command(label="Refine Module", command=self.on_graph_refine)
        self.graph_menu.add_command(label="Implement Function", command=self.on_graph_implement)

    # --- [修正] 對外 API 介面 ---

    def clear_all_editors(self):
        """[Fix] 給 MainWindow 呼叫，用來清空所有開啟的檔案"""
        for tab in self.editor_notebook.tabs():
            self.editor_notebook.forget(tab)
        self.opened_files_map.clear()
        self.path_to_frame.clear()
        # 重設預設頁
        self.open_file("Welcome", "Select a file from Project Explorer to edit.", None)

    def get_active_code(self):
        """[Fix] 給 IntelligencePanel 呼叫，獲取當前正在編輯的程式碼"""
        try:
            current_tab = self.editor_notebook.select()
            if not current_tab: return ""
            # current_tab 是一個 widget name (string)，我們需要找到對應的 widget instance
            # 在 ttk.Notebook 中，select() 回傳的是 identifier
            # 我們需要遍歷子元件找到 ScrolledText
            frame = self.editor_notebook.nametowidget(current_tab)
            for child in frame.winfo_children():
                if isinstance(child, scrolledtext.ScrolledText):
                    return child.get("1.0", tk.END).strip()
            return ""
        except Exception as e:
            print(f"Error getting active code: {e}")
            return ""

    # --- Editor Logic ---

    def on_editor_tab_change(self, event):
        try:
            current_tab = self.editor_notebook.select()
            # 這裡 current_tab 是 widget name
            # 我們存的 key 是 frame object，需要轉換或者直接用 name
            # 為了穩健，我們在此用 widget instance 比較
            target_widget = self.editor_notebook.nametowidget(current_tab)
            file_path = self.opened_files_map.get(target_widget)

            if file_path:
                self.lbl_current_file.config(text=file_path)
            else:
                self.lbl_current_file.config(text="(No File)")
        except:
            pass

    def close_current_file(self):
        try:
            current_tab = self.editor_notebook.select()
            if not current_tab: return
            target_widget = self.editor_notebook.nametowidget(current_tab)

            file_path = self.opened_files_map.pop(target_widget, None)
            if file_path and file_path in self.path_to_frame:
                del self.path_to_frame[file_path]

            self.editor_notebook.forget(current_tab)
        except Exception as e:
            print(f"Error closing tab: {e}")

    def open_file(self, title, content, file_path):
        if file_path and file_path in self.path_to_frame:
            self.editor_notebook.select(self.path_to_frame[file_path])
            return

        frame = ttk.Frame(self.editor_notebook)
        txt = scrolledtext.ScrolledText(
            frame, font=("Consolas", 11),
            bg=self.colors['editor_bg'], fg="#a9b7c6",
            insertbackground="white", selectbackground="#214283"
        )
        txt.pack(fill=tk.BOTH, expand=True)
        txt.insert(tk.END, content)

        self.editor_notebook.add(frame, text=title)
        self.editor_notebook.select(frame)

        if file_path:
            self.opened_files_map[frame] = file_path
            self.path_to_frame[file_path] = frame
        else:
            self.opened_files_map[frame] = title
            self.path_to_frame[title] = frame

    # --- Graph Logic (保持不變) ---
    def on_tab_change(self, event):
        selected_tab = self.notebook.index(self.notebook.select())
        if selected_tab == 1:
            self.draw_dependency_graph()

    # ... (其餘 Graph 相關程式碼 draw_dependency_graph, _generate_colors 等與上一版相同，請保留) ...
    # 為了簡潔，這裡省略重複的 Graph 代碼，請確保它們還在

    def _generate_colors(self, n):
        palette = ["#ff79c6", "#bd93f9", "#8be9fd", "#50fa7b", "#ffb86c", "#ff5555", "#f1fa8c", "#6272a4", "#4a88c7", "#e06c75", "#98c379", "#61afef"]
        return [palette[i % len(palette)] for i in range(n)]

    def _get_contrast_color(self, hex_color):
        hex_color = hex_color.lstrip('#')
        try:
            rgb = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
            comp = (255 - rgb[0], 255 - rgb[1], 255 - rgb[2])
            return '#%02x%02x%02x' % comp
        except: return "white"

    def draw_module_view(self):
        self.canvas.delete("all")
        self._hit_areas = []

        nodes, edges = self.mediator.meta.get_module_dependencies()
        if not nodes:
            self.canvas.create_text(400, 300, text="No module data.", fill="#666")
            return

        # 圓形佈局
        width = self.canvas.winfo_width()
        height = self.canvas.winfo_height()
        center_x, center_y = width / 2, height / 2
        radius = min(width, height) / 3

        angle_step = 2 * math.pi / len(nodes)
        node_pos = {}

        # Draw Nodes
        for i, node in enumerate(nodes):
            angle = i * angle_step
            x = center_x + radius * math.cos(angle)
            y = center_y + radius * math.sin(angle)
            node_pos[node] = (x, y)

            # 模組圓圈比較大
            self.canvas.create_oval(x-30, y-30, x+30, y+30, fill="#4a88c7", outline="white", width=2)
            self.canvas.create_text(x, y, text=node, fill="white", font=("Arial", 10, "bold"))

        # Draw Edges
        for u, v in edges:
            if u in node_pos and v in node_pos:
                x1, y1 = node_pos[u]
                x2, y2 = node_pos[v]
                self.canvas.create_line(x1, y1, x2, y2, arrow=tk.LAST, fill="#888", width=2)

    def draw_dependency_graph(self):
        if self.view_mode.get() == "module":
            self.draw_module_view()
        else:
            self.canvas.delete("all")
            self._hit_areas = []
            data = self.mediator.meta.get_function_distribution()
            if not data:
                self.canvas.create_text(400, 300, text="No data.", fill="#666", font=("Arial", 14))
                return

            modules = list(data.keys())
            colors = self._generate_colors(len(modules))
            mod_color_map = {mod: col for mod, col in zip(modules, colors)}

            width = self.canvas.winfo_width()
            height = self.canvas.winfo_height()
            if width < 100: width = 800
            if height < 100: height = 600
            center_x, center_y = width / 2, height / 2
            max_radius = min(width, height) / 2 - 50
            total_modules = len(modules)
            angle_per_mod = (2 * math.pi) / total_modules if total_modules > 0 else 0

            for i, mod in enumerate(modules):
                funcs = data[mod]
                start_angle = i * angle_per_mod
                color = mod_color_map[mod]
                for j, func in enumerate(funcs):
                    random.seed(hash(mod + func))
                    theta = start_angle + (angle_per_mod * random.random())
                    r = max_radius * (0.3 + 0.6 * random.random())
                    x = center_x + r * math.cos(theta)
                    y = center_y + r * math.sin(theta)
                    node_r = 10
                    if self.selected_node == (func, mod):
                        contrast = self._get_contrast_color(color)
                        self.canvas.create_oval(x - node_r - 4, y - node_r - 4, x + node_r + 4, y + node_r + 4, outline=contrast, width=3)
                    self.canvas.create_oval(x - node_r, y - node_r, x + node_r, y + node_r, fill=color, outline="white", width=1)
                    self.canvas.create_text(x, y + 18, text=func, fill="#ccc", font=("Consolas", 8))
                    self._hit_areas.append((x - node_r, y - node_r, x + node_r, y + node_r, func, mod, color))
            self._draw_legend(width, height, modules, mod_color_map)

    def _draw_legend(self, w, h, modules, color_map):
        legend_x = w - 200
        legend_y = h - (len(modules) * 20) - 20
        self.canvas.create_rectangle(legend_x - 10, legend_y - 10, w - 10, h - 10, fill="#222", outline="#444")
        self.canvas.create_text(legend_x, legend_y - 20, text="[ Module Legend ]", fill="white", anchor="nw")
        for i, mod in enumerate(modules):
            y = legend_y + i * 20
            self.canvas.create_rectangle(legend_x, y, legend_x+12, y+12, fill=color_map[mod], outline="")
            self.canvas.create_text(legend_x+20, y, text=mod, fill="#ccc", anchor="nw")

    # --- [關鍵修正] 補上缺失的 helper method ---
    def _get_spec_path(self, mod_name):
        """
        搜尋模組的 spec.json 路徑。
        優先搜尋 workspace/mod_name/spec.json
        其次搜尋 workspace/*/mod_name/spec.json
        """
        root = self.mediator.meta.workspace_root

        # 1. 檢查根目錄下
        p1 = os.path.join(root, mod_name, "spec.json")
        if os.path.exists(p1): return p1

        # 2. 檢查第一層子目錄下 (針對專案資料夾結構)
        for d in os.listdir(root):
            d_path = os.path.join(root, d)
            if os.path.isdir(d_path):
                p2 = os.path.join(d_path, mod_name, "spec.json")
                if os.path.exists(p2): return p2

        return None

    def on_canvas_click(self, event):
        clicked_something = False
        for x1, y1, x2, y2, func, mod, color in self._hit_areas:
            if x1 <= event.x <= x2 and y1 <= event.y <= y2:
                self.selected_node = (func, mod)
                self.draw_dependency_graph()

                # [Fix 4] 通知 ControlPanel 更新按鈕
                spec_path = self._get_spec_path(mod)
                if spec_path:
                    self.mediator.controls.update_context_button('impl', (func, spec_path))

                self.graph_menu.post(event.x_root, event.y_root)
                clicked_something = True
                break

        if not clicked_something:
            if self.selected_node:
                self.selected_node = None
                self.draw_dependency_graph()

                # [Fix 4] 恢復預設按鈕
                self.mediator.controls.update_context_button('arch', None)

            try: self.graph_menu.unpost()
            except: pass

    def on_graph_refine(self):
        if not self.selected_node: return
        _, mod = self.selected_node
        self.mediator.run_async(lambda: self.mediator.meta.refine_module(mod, cancel_event=self.mediator._current_cancel_flag))

    def on_graph_implement(self):
        if not self.selected_node: return
        func, mod = self.selected_node
        # 簡易反推 spec path，實際應更嚴謹
        root = self.mediator.meta.workspace_root
        spec_path = None
        for d in os.listdir(root): # 檢查第一層子目錄
             potential = os.path.join(root, d, mod, "spec.json")
             if os.path.exists(potential): spec_path = potential; break
        if not spec_path: # 再試試直接在 root 下
             potential = os.path.join(root, mod, "spec.json")
             if os.path.exists(potential): spec_path = potential

        if spec_path:
            self.mediator.run_async(lambda: self.mediator.meta.implement_functions(spec_path, [func], cancel_event=self.mediator._current_cancel_flag))

######################################################################

#################### 檔案: GUI/ProjectExplorer.py ####################
import tkinter as tk
from tkinter import ttk
import os
import json
import datetime

class ProjectExplorer:
    def __init__(self, parent, mediator):
        self.mediator = mediator
        self.meta = mediator.meta
        self._last_snapshot = {}
        self._is_refreshing = False

        # Loading 動畫相關
        self._loading_items = set() # 存放正在生成的 item ID
        self._spinner_chars = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]
        self._spinner_idx = 0

        self.frame = ttk.LabelFrame(parent, text="Project Explorer")

        self.tree = ttk.Treeview(self.frame, selectmode="extended")
        self.tree.pack(fill=tk.BOTH, expand=True)

        self.tree.bind("<<TreeviewSelect>>", self.on_select)
        self.tree.bind("<Button-3>", self.show_context_menu)
        self.tree.bind("<Button-1>", self._on_tree_click)

        self._init_menu()
        self.frame.after(1000, self._monitor_loop)

        # 啟動動畫迴圈
        self._animate_loading()


    def _animate_loading(self):
        """處理旋轉動畫"""
        if self._loading_items:
            char = self._spinner_chars[self._spinner_idx]
            self._spinner_idx = (self._spinner_idx + 1) % len(self._spinner_chars)

            # 對於需要移除的 item (可能任務已結束但尚未刷新)，做個清理
            to_remove = []
            for item_id in self._loading_items:
                if not self.tree.exists(item_id):
                    to_remove.append(item_id)
                    continue

                # 更新文字，加上 spinner
                # 我們需要保留原始文字...這有點麻煩，簡單做法是 tag 識別
                current_text = self.tree.item(item_id, "text")
                # 如果已經有 spinner，替換掉
                # 假設 spinner 加在最後 "func_name  ⠋"
                clean_text = current_text.split("  ")[0]
                self.tree.item(item_id, text=f"{clean_text}  {char}")

            for i in to_remove:
                self._loading_items.discard(i)

        self.frame.after(100, self._animate_loading)

    def set_item_loading(self, name, is_loading):
        """
        [修正] 支援函式或模組名稱的 Loading。
        name: func_name 或 module_name
        """
        for item_id in self.tree.get_children(): # Project
            # 檢查是不是模組
            item_text = self.tree.item(item_id, "text").split(" ")[0]
            if item_text == name: # 這是根節點(Project)，通常不會 loading，略過
                pass

            for mod_id in self.tree.get_children(item_id): # Module
                mod_text = self.tree.item(mod_id, "text").split(" ")[0]
                if mod_text == name:
                    # 找到模組
                    if is_loading: self._loading_items.add(mod_id)
                    else: self._loading_items.discard(mod_id)
                    # 這裡不 return，因為可能還有同名的 func (雖然機率低)

                for func_id in self.tree.get_children(mod_id): # Function
                    func_text = self.tree.item(func_id, "text").split(" ")[0]
                    if func_text == name:
                        if is_loading: self._loading_items.add(func_id)
                        else: self._loading_items.discard(func_id)
                        return

    def _get_status_map(self, mod_dir):
        """讀取該模組的 .status.json"""
        status_path = os.path.join(mod_dir, ".status.json")
        if os.path.exists(status_path):
            try:
                with open(status_path, 'r') as f:
                    return json.load(f)
            except: pass
        return {}

    def refresh_tree(self):
        if self._is_refreshing: return
        self._is_refreshing = True
        try:
            expanded_nodes = self._save_expanded_state()
            # 清空時也要清空 loading set，避免 ID 參照錯誤
            self._loading_items.clear()
            self.tree.delete(*self.tree.get_children())

            data = self.meta.get_project_tree()
            if not data: return

            proj_name = data.get('project_name', 'Project')
            root = self.tree.insert("", "end", text=proj_name, open=True, values=("project",))

            # 推斷專案根目錄
            if self.meta.current_architecture_path:
                project_base_dir = os.path.dirname(self.meta.current_architecture_path)
            else:
                project_base_dir = self.meta.workspace_root

            modules = data.get('modules', [])
            for mod in modules:
                mod_name = mod['name']
                mod_node = self.tree.insert(root, "end", text=mod_name, open=False, values=("module",))

                mod_dir = os.path.join(project_base_dir, mod_name)
                spec_path = os.path.join(mod_dir, "spec.json")

                if os.path.exists(spec_path):
                    self.tree.item(mod_node, values=("module", spec_path))

                    # [新增] 讀取狀態檔
                    status_map = self._get_status_map(mod_dir)

                    try:
                        with open(spec_path, 'r', encoding='utf-8') as f:
                            spec = json.load(f)

                        for func in spec.get('functions', []):
                            fname = func['name']
                            display_text = fname

                            # [新增] 檢查狀態並打勾
                            if status_map.get(fname) == "implemented":
                                display_text += " ✔"

                            self.tree.insert(mod_node, "end", text=display_text, values=("function", spec_path))
                    except Exception as e:
                        print(f"[Explorer] Spec load error: {e}")

            self._restore_expanded_state(expanded_nodes)
        finally:
            self._is_refreshing = False

    # ... 其他 helper methods (_init_menu, on_select, context menu 等) 保持原樣 ...
    # 這裡省略以節省篇幅，請保留原本的代碼

    def _init_menu(self):
        self.menu = tk.Menu(self.frame, tearoff=0)
        self.menu.add_command(label="Refine Selected Modules (Phase 2)", command=self.on_refine)
        self.menu.add_command(label="Implement Selected Functions (Phase 3)", command=self.on_implement)
        self.menu.add_separator()
        self.menu.add_command(label="Show Architecture JSON", command=self.show_arch_json)

    def _on_tree_click(self, event):
        try: self.menu.unpost()
        except: pass

    def show_context_menu(self, event):
        item = self.tree.identify_row(event.y)
        if item:
            if item not in self.tree.selection(): self.tree.selection_set(item)
            self.tree.focus_set()
            self.menu.post(event.x_root, event.y_root)

    def set_workspace(self, path):
        self._last_snapshot = {}
        self.tree.delete(*self.tree.get_children())
        self.frame.after_idle(self.refresh_tree)

    def _monitor_loop(self):
        if not self.frame.winfo_exists(): return
        try:
            if self.meta.workspace_root:
                snap = 0
                if self.meta.current_architecture_path and os.path.exists(self.meta.current_architecture_path):
                     snap = os.path.getmtime(self.meta.current_architecture_path)
                # 這裡可以加入對 .status.json 的監控，但為了效能，我們依賴操作觸發刷新
                if snap != self._last_snapshot.get('arch', 0):
                    self._last_snapshot['arch'] = snap
                    self.frame.after_idle(self.refresh_tree)
        except: pass
        self.frame.after(2000, self._monitor_loop)

    def _save_expanded_state(self):
        expanded = set()
        for child in self.tree.get_children():
            for grand_child in self.tree.get_children(child):
                if self.tree.item(grand_child, 'open'):
                    expanded.add(self.tree.item(grand_child, 'text'))
            if self.tree.item(child, 'open'):
                expanded.add("root_project")
        return expanded

    def _restore_expanded_state(self, expanded_set):
        for child in self.tree.get_children():
            if "root_project" in expanded_set:
                self.tree.item(child, open=True)
            for grand_child in self.tree.get_children(child):
                # 因為文字可能加上了 ✔，所以我們要比對原始名稱
                item_text = self.tree.item(grand_child, 'text').split(" ")[0]
                if item_text in expanded_set:
                    self.tree.item(grand_child, open=True)

    def on_select(self, event):
        selected_items = self.tree.selection()
        if not selected_items: return
        item = selected_items[0]
        values = self.tree.item(item, "values")
        text = self.tree.item(item, "text").split(" ")[0] # 去除勾勾或 spinner
        if not values: return
        item_type = values[0]
        file_path = None
        content_to_show = ""
        title = text
        if item_type == "function":
            spec_path = values[1]
            mod_dir = os.path.dirname(spec_path)
            fname = "__init_logic__.py" if text == "__init__" else f"{text}.py"
            file_path = os.path.join(mod_dir, fname)
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f: content_to_show = f.read()
            else: content_to_show = "# Source code not found."
        elif item_type == "module":
            if len(values) > 1:
                spec_path = values[1]
                file_path = spec_path
                if os.path.exists(spec_path):
                    with open(spec_path, 'r', encoding='utf-8') as f: content_to_show = json.dumps(json.load(f), indent=4, ensure_ascii=False)
        elif item_type == "project":
            if self.meta.current_architecture_path:
                file_path = self.meta.current_architecture_path
                with open(file_path, 'r', encoding='utf-8') as f: content_to_show = json.dumps(json.load(f), indent=4, ensure_ascii=False)
        if content_to_show: self.mediator.workspace.open_file(title, content_to_show, file_path)

    def show_arch_json(self):
        if self.meta.current_architecture_path:
            with open(self.meta.current_architecture_path, 'r') as f:
                content = json.dumps(json.load(f), indent=4)
                self.mediator.workspace.open_file("architecture.json", content, self.meta.current_architecture_path)

    def on_refine(self):
        items = self.tree.selection()
        target_modules = []
        for item in items:
            vals = self.tree.item(item, "values")
            if vals and vals[0] == "module":
                target_modules.append(self.tree.item(item, "text"))

        if not target_modules: return

        def task():
            for mod in target_modules:
                if self.mediator._current_cancel_flag.is_set(): break
                self.mediator.log(f"[Action] Refining module '{mod}'...")

                res = self.mediator.meta.refine_module(mod, cancel_event=self.mediator._current_cancel_flag)

                if res is None:
                    self.mediator.log(f"[Fail] Refinement of {mod} failed/blocked.")

            self.frame.after(0, self.refresh_tree) # 刷新會清除 loading

        self.mediator.run_async(task)

    def on_implement(self):
        items = self.tree.selection()
        # tasks 結構: { (mod_name, spec_path): [func_name1, func_name2] }
        tasks = {}

        for item in items:
            vals = self.tree.item(item, "values")
            if vals and vals[0] == "function":
                # 去除狀態符號
                raw_text = self.tree.item(item, "text")
                fname = raw_text.split(" ")[0]

                # 如果已經實作過 (有 ✔)，詢問是否重新實作？(這裡簡化：直接允許)

                spec_path = vals[1]
                # 獲取模組名稱 (上一層節點的 text)
                parent_id = self.tree.parent(item)
                mod_name = self.tree.item(parent_id, "text")

                key = (mod_name, spec_path)
                if key not in tasks: tasks[key] = []
                tasks[key].append(fname)

        if not tasks: return

        # 1. 檢查依賴 & 排程
        for (mod_name, spec_path), funcs in tasks.items():

            # [依賴鎖定]
            if not self.meta.check_dependencies_met(mod_name):
                msg = f"Cannot implement module '{mod_name}'.\nDependencies not met.\n\nPlease implement dependent modules first."
                self.mediator.log(f"[Blocked] {msg}")
                # [Fix 5] 彈窗警告
                tk.messagebox.showwarning("Dependency Error", msg)
                continue

            # 2. 為每個函式建立獨立任務
            for func in funcs:
                self.set_item_loading(func, True) # 開始旋轉

                # 使用 closure 捕捉變數
                def make_task(s_path, f_name, m_name):
                    def task_func():
                        # [Fix 2] 開始生成時顯示
                        self.mediator.log(f"[Action] Generating code for {f_name} (in {m_name})...")

                        result = self.meta.coder.implement_function_direct(
                            s_path, f_name,
                            self.meta.model_config['coder'],
                            cancel_event=self.mediator._current_cancel_flag
                        )
                        return result

                    def success_cb():
                        # 停止旋轉，刷新樹狀圖 (會自動變為 ✔)
                        self.set_item_loading(f_name, False)
                        self.refresh_tree() # 刷新以讀取 .status.json 更新 UI

                        # [新增] 自動在編輯器開啟
                        mod_dir = os.path.dirname(s_path)
                        code_path = os.path.join(mod_dir, "__init_logic__.py" if f_name == "__init__" else f"{f_name}.py")
                        if os.path.exists(code_path):
                            with open(code_path, 'r', encoding='utf-8') as f:
                                code = f.read()
                            self.mediator.workspace.open_file(f_name, code, code_path)

                        # [新增] 顯示詳細資訊到 Intelligence Panel
                        # 我們需要讀取最新的 status 來獲取 entropy
                        status_path = os.path.join(mod_dir, ".status.json")
                        try:
                            with open(status_path, 'r') as f: st = json.load(f)
                            info = st.get(f_name, {})
                            self.mediator.log(f"[Success] {f_name} v{info.get('version')} (Entropy: {info.get('entropy')})")
                        except: pass

                    return task_func, success_cb

                t_func, s_cb = make_task(spec_path, func, mod_name)

                # 加入 MainWindow 的 Queue
                self.mediator.run_async(t_func, success_callback=s_cb)

######################################################################

#################### 檔案: GUI/ControlPanel.py ####################
import tkinter as tk
from tkinter import ttk

class ControlPanel:
    def __init__(self, parent, mediator):
        self.mediator = mediator
        self.colors = getattr(mediator, 'colors', {'bg': '#333', 'fg': '#eee', 'editor_bg': '#1e1e1e'})

        self.frame = tk.Frame(parent, bg=self.colors['bg'])
        self.frame.pack(fill=tk.X)

        # Requirement Input
        tk.Label(self.frame, text="Requirement Prompt:", bg=self.colors['bg'], fg=self.colors['fg']).pack(anchor="w", padx=5)
        self.entry = tk.Text(self.frame, height=3, bg=self.colors['editor_bg'], fg="white", insertbackground="white", relief=tk.FLAT)
        self.entry.pack(fill=tk.X, padx=5, pady=2)

        # Control Area
        ctrl_frame = tk.Frame(self.frame, bg=self.colors['bg'])
        ctrl_frame.pack(fill=tk.X, pady=5)

        self.status_lbl = tk.Label(ctrl_frame, text="Ready", fg="#4a88c7", bg=self.colors['bg'])
        self.status_lbl.pack(side=tk.LEFT, padx=5)

        # [Fix 4] 動態按鈕：預設是 Architecture
        self.action_btn = ttk.Button(ctrl_frame, text="GENERATE ARCHITECTURE", command=self.on_click)
        self.action_btn.pack(side=tk.RIGHT, padx=5)

        # 儲存當前按鈕的模式 ('arch', 'impl', 'refine')
        self.current_action_mode = 'arch'
        self.current_target = None # 儲存目標 (spec path, func name 等)

        self.is_running = False
        self.current_mode = tk.StringVar(value="creation")
        self._init_mode_switcher()

    def _init_mode_switcher(self):
        # (保持不變)
        mode_frame = tk.Frame(self.frame, bg=self.colors['bg'])
        mode_frame.pack(fill=tk.X, pady=(0, 5), padx=5)
        modes = [("Creation", "creation"), ("Gen. Test", "general_test"), ("Static Eval", "static_eval"), ("Runtime", "runtime_analysis"), ("Chaos", "chaos_test")]
        btn_bg, select_color = "#444", "#666"
        for text, mode_val in modes:
            tk.Radiobutton(mode_frame, text=text, value=mode_val, variable=self.current_mode, indicatoron=0, bg=btn_bg, fg=self.colors['fg'], selectcolor=select_color, activebackground=select_color, activeforeground="white", bd=0, command=self.on_mode_switch).pack(side=tk.LEFT, fill=tk.X, expand=True, padx=1)

    def on_mode_switch(self):
        if hasattr(self.mediator, 'log'):
            self.mediator.log(f"Switched View Mode to: {self.current_mode.get()}")

    def set_status(self, msg):
        self.status_lbl.config(text=msg)

    def set_running_state(self, running: bool):
        self.is_running = running
        if running:
            self.action_btn.config(text="STOP GENERATION")
            self.status_lbl.config(fg="#ff5555")
        else:
            # 恢復原本的按鈕文字
            self._restore_button_text()
            self.status_lbl.config(fg="#4a88c7")

    def _restore_button_text(self):
        if self.current_action_mode == 'arch':
            self.action_btn.config(text="GENERATE ARCHITECTURE")
        elif self.current_action_mode == 'impl':
            self.action_btn.config(text=f"IMPLEMENT FUNCTION: {self.current_target[0]}")
        elif self.current_action_mode == 'refine':
            self.action_btn.config(text=f"REFINE MODULE: {self.current_target}")

    # [Fix 4] 對外 API：更新按鈕上下文
    def update_context_button(self, mode: str, target=None):
        """
        mode: 'arch', 'impl', 'refine'
        target: 相關資料 (如函式名)
        """
        self.current_action_mode = mode
        self.current_target = target
        if not self.is_running:
            self._restore_button_text()

    def on_click(self):
        if self.is_running:
            self.mediator.stop_current_task()
        else:
            # 根據當前模式分派任務
            if self.current_action_mode == 'arch':
                self.on_generate_arch()
            elif self.current_action_mode == 'impl':
                # target: (func_name, spec_path)
                func, spec = self.current_target
                # 呼叫 ProjectExplorer 的 implement 邏輯 (透過 mediator)
                # 這裡直接呼叫 meta 比較快
                self.on_generate_impl(spec, func)
            elif self.current_action_mode == 'refine':
                mod = self.current_target
                self.on_generate_refine(mod)

    def on_generate_arch(self):
        req = self.entry.get("1.0", tk.END).strip()
        if not req: return
        def task():
            self.mediator.log("Generating Architecture...")
            if self.mediator._current_cancel_flag.is_set(): return
            res = self.mediator.meta.init_project(req)
            self.mediator.log(f"Saved: {res.structure_file_path}")
        def on_success():
            if hasattr(self.mediator, 'nav'): self.mediator.nav.refresh_tree()
        self.mediator.run_async(task, success_callback=on_success)

    def on_generate_impl(self, spec_path, func_name):
        # 借用 ProjectExplorer 的 loading 邏輯比較麻煩，這裡直接觸發 meta
        # 但為了保持 UI 一致性，最好還是走 ProjectExplorer 的邏輯
        # 簡單做法：發送請求給 Nav
        if hasattr(self.mediator, 'nav'):
            # 模擬選取並執行
            # 但這裡我們直接調用 meta，並手動設置 loading
            self.mediator.nav.set_item_loading(func_name, True)

            def task():
                self.mediator.log(f"[Start] Implementing {func_name}...")
                self.mediator.meta.implement_functions(spec_path, [func_name], cancel_event=self.mediator._current_cancel_flag)
                self.mediator.nav.frame.after(0, self.mediator.nav.refresh_tree)

            self.mediator.run_async(task)

    def on_generate_refine(self, mod_name):
        def task():
            self.mediator.log(f"[Start] Refining {mod_name}...")
            self.mediator.meta.refine_module(mod_name, cancel_event=self.mediator._current_cancel_flag)
            self.mediator.nav.frame.after(0, self.mediator.nav.refresh_tree)
        self.mediator.run_async(task)

######################################################################

#################### 檔案: System/OllamaManager.py ####################
import subprocess
import time
import os
import signal
import sys
import requests

class OllamaManager:
    def __init__(self):
        self.process = None
        self.log_func = print # 預設輸出到 console，稍後由 MetaCoder 覆蓋

    def set_logger(self, func):
        self.log_func = func

    def is_running(self):
        """檢查 Ollama 服務是否回應"""
        try:
            # 嘗試連線一個輕量級 API
            requests.get("http://localhost:11434/api/tags", timeout=1)
            return True
        except:
            return False

    def start_service(self):
        """啟動 ollama serve"""
        if self.is_running():
            self.log_func("[OllamaManager] Service already running.")
            return

        self.log_func("[OllamaManager] Starting 'ollama serve'...")
        try:
            # 使用 shell=True 在某些環境下比較容易抓到 path，但要小心子進程管理
            # 這裡使用 creationflags 確保可以殺乾淨 (Windows)
            kwargs = {}
            if sys.platform == "win32":
                kwargs['creationflags'] = subprocess.CREATE_NEW_PROCESS_GROUP

            self.process = subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                **kwargs
            )

            # 等待服務就緒
            for _ in range(10): # 最多等 10 秒
                if self.is_running():
                    self.log_func("[OllamaManager] Service is READY.")
                    return
                time.sleep(1)

            self.log_func("[OllamaManager] Warning: Service start timed out, but proceeding.")

        except Exception as e:
            self.log_func(f"[OllamaManager] Start failed: {e}")

    def kill_service(self):
        """核選項：殺死進程"""
        self.log_func("[OllamaManager] KILLING Ollama Service...")

        # 1. 先殺 Python 掌握的子進程
        if self.process:
            try:
                self.process.kill() # SIGKILL
                self.process.terminate()
            except: pass
            self.process = None

        # 2. 系統級強制清理 (防止殭屍進程或早已存在的服務)
        try:
            if sys.platform == "win32":
                os.system("taskkill /F /IM ollama.exe /T")
                os.system("taskkill /F /IM ollama_app.exe /T") # 有些版本叫這個
            else:
                os.system("pkill -9 ollama")
        except Exception as e:
            self.log_func(f"[OllamaManager] System kill failed: {e}")

        self.log_func("[OllamaManager] Service TERMINATED.")

######################################################################

#################### 檔案: System/VersionController.py ####################
import os
import datetime
from typing import List, Dict, Optional
import git # pip install gitpython

class VersionController:
    def __init__(self, workspace_dir: str = "./vibe_workspace"):
        self.workspace_dir = os.path.abspath(workspace_dir)
        if not os.path.exists(self.workspace_dir):
            os.makedirs(self.workspace_dir)

        # 初始化 Git 儲存庫
        try:
            self.repo = git.Repo(self.workspace_dir)
        except git.exc.InvalidGitRepositoryError:
            print(f"[*] Initializing new Git repo in {self.workspace_dir}")
            self.repo = git.Repo.init(self.workspace_dir)
            self._setup_gitignore()

    def _setup_gitignore(self):
        """建立 .gitignore 防止追蹤不必要的檔案"""
        gitignore_path = os.path.join(self.workspace_dir, ".gitignore")
        if not os.path.exists(gitignore_path):
            with open(gitignore_path, "w") as f:
                f.write("__pycache__/\n*.pyc\n.env\n.DS_Store\n")
            self.repo.index.add([gitignore_path])
            self.repo.index.commit("Initial commit: Add .gitignore")

    def archiveVersion(self, message: str) -> str:
        """
        [歸檔] 將目前的專案狀態提交 (Commit)
        Args:
            message: 提交訊息 (例如 "Initial structure for Auth module")
        Returns:
            commit_hash (short sha)
        """
        # 1. 加入所有變更 (git add .)
        # untracked_files 處理新增檔案，diff(None) 處理修改檔案
        if self.repo.is_dirty(untracked_files=True):
            self.repo.git.add(A=True) # A=True 相當於 add .

            # 2. 提交
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            full_msg = f"[{timestamp}] {message}"
            commit = self.repo.index.commit(full_msg)

            print(f"[VersionController] Archived: {full_msg} (Hash: {commit.hexsha[:7]})")
            return commit.hexsha
        else:
            print("[VersionController] No changes to archive.")
            return self.repo.head.commit.hexsha

    def rollbackVersion(self, commit_hash: str, file_path: str = None) -> bool:
        """
        [回滾] 將專案或特定檔案回復到指定版本
        Args:
            commit_hash: 目標版本的雜湊值
            file_path: 指定檔案路徑 (若為 None 則回滾整個專案)
        """
        try:
            if file_path:
                # 回滾單一檔案：git checkout <commit> -- <path>
                # 需要將絕對路徑轉換為相對於 repo 的路徑
                rel_path = os.path.relpath(file_path, self.workspace_dir)
                self.repo.git.checkout(commit_hash, "--", rel_path)
                print(f"[VersionController] Rolled back file '{rel_path}' to {commit_hash[:7]}")
            else:
                # 回滾整個專案：git reset --hard <commit>
                # 注意：這會丟棄所有未提交的變更，請確保 rollback 前有 archive
                self.repo.git.reset("--hard", commit_hash)
                print(f"[VersionController] Rolled back PROJECT to {commit_hash[:7]}")
            return True
        except Exception as e:
            print(f"[!] Rollback failed: {e}")
            return False

    def getHistory(self, limit: int = 10) -> List[Dict]:
        """獲取最近的提交紀錄供 GUI 顯示"""
        history = []
        for commit in list(self.repo.iter_commits(max_count=limit)):
            history.append({
                "hash": commit.hexsha,
                "short_hash": commit.hexsha[:7],
                "message": commit.message.strip(),
                "date": datetime.datetime.fromtimestamp(commit.committed_date).strftime("%Y-%m-%d %H:%M:%S")
            })
        return history

######################################################################

#################### 檔案: Static/ASTGraph.py ####################
import networkx as nx
import matplotlib.pyplot as plt
import uuid

class ASTGraph:
    """
    ASTGraph: 用於儲存虛擬碼流程圖的資料結構。
    基於 NetworkX 的 DiGraph (有向圖) 實作。
    """

    def __init__(self):
        # 初始化一個有向圖
        self.graph = nx.DiGraph()
        # 記錄起始節點 ID (可選)
        self.root_id = None

# 修改原本的 add_node，增加 **kwargs
    def add_node(self, content: str, node_type: str = "process", node_id: str = None, **kwargs) -> str:
        if node_id is None:
            node_id = str(uuid.uuid4())[:8]

        # [修改點] 確保將 kwargs 傳遞給 NetworkX 的 add_node
        # 原本可能是: self.graph.add_node(node_id, label=content, type=node_type)
        self.graph.add_node(node_id, label=content, type=node_type, **kwargs)

        if self.root_id is None:
            self.root_id = node_id

        return node_id

    def add_edge(self, source_id: str, target_id: str, condition: str = None):
        """
        建立兩個節點之間的流向 (邊)。

        Args:
            source_id (str): 來源節點 ID
            target_id (str): 目標節點 ID
            condition (str, optional): 邊的標籤 (例如: "Yes", "No", "True")，用於判斷式分支。
        """
        if source_id not in self.graph or target_id not in self.graph:
            raise ValueError("Source or Target ID does not exist in the graph.")

        # NetworkX 允許在邊上儲存屬性
        attr = {}
        if condition:
            attr['label'] = condition

        self.graph.add_edge(source_id, target_id, **attr)

    def get_node_info(self, node_id: str) -> dict:
        """取得特定節點的詳細資訊"""
        if node_id in self.graph:
            return self.graph.nodes[node_id]
        return None

    def get_next_steps(self, node_id: str) -> list:
        """
        取得某節點的下一步驟 (Outgoing edges)。
        回傳格式: [(target_id, condition), ...]
        """
        successors = []
        # 遍歷該節點指出的所有邊
        for _, target, data in self.graph.out_edges(node_id, data=True):
            condition = data.get('label', None)
            successors.append((target, condition))
        return successors

    def visualize(self):
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'SimHei']
        #解決負號亂碼問題 (這是 CJK 字體常見的額外步驟)
        plt.rcParams['axes.unicode_minus'] = False
        """
        使用 Matplotlib 繪製流程圖。
        根據節點類型給予不同顏色與形狀。
        """
        if self.graph.number_of_nodes() == 0:
            print("Graph is empty.")
            return

        pos = nx.spring_layout(self.graph, seed=42, k=0.5, iterations=50)  # 節點佈局演算法
        plt.figure(figsize=(16, 10))
        # 1. 定義樣式映射
        color_map = []
        node_shapes = []
        labels = {}

        type_color = {
            'start': '#88d8b0',    # 綠色
            'end': '#ff6f69',      # 紅色
            'process': '#a8e6cf',  # 淺青
            'decision': '#ffeead', # 黃色 (菱形通常用於判斷，但在 nx 繪圖簡單處理用顏色區分)
            'io': '#dcedc1',       # 淺綠
            'import': '#e6e6fa',   # 淺紫色 (Lavender)，代表外部引入
            'function': '#97c2fc', # 淡藍色，用於函式定義
            'class': '#ffe156',    # 金黃色，用於類別定義
        }

        for node, data in self.graph.nodes(data=True):
            n_type = data.get('type', 'process')
            color_map.append(type_color.get(n_type, '#cccccc'))
            labels[node] = data.get('label', node)

        node_collection = nx.draw_networkx_nodes(self.graph, pos,
                                                 node_color=color_map,
                                                 node_size=2500,
                                                 alpha=0.9)

        # 手動設定節點的 Z-order (較低)
        if node_collection is not None:
            node_collection.set_zorder(2)

        # 2. 繪製節點標籤 (Labels) - 捕捉返回的 Text 對象
        # Note: 標籤在 Matplotlib 中是 Text 物件
        label_handles = nx.draw_networkx_labels(self.graph, pos, labels,
                                                font_size=9)

        # 手動設定標籤的 Z-order (略高於節點)
        if label_handles:
            for text_obj in label_handles.values():
                text_obj.set_zorder(3)

        # 3. 繪製邊和箭頭 (Edges) - 捕捉返回的 Collection 對象
        # 注意: 此處不再使用 zorder=... 參數
        edge_collection = nx.draw_networkx_edges(self.graph, pos,
                                                 edge_color='gray',
                                                 arrows=True,
                                                 arrowsize=20)

        # 手動設定邊和箭頭的 Z-order (最高，確保在節點之上)
        if edge_collection is not None:
           for edge in edge_collection:
               edge.set_zorder(4)

        # 5. 繪製邊上的文字 (True/False 等條件)
        edge_labels = nx.get_edge_attributes(self.graph, 'label')
        nx.draw_networkx_edge_labels(self.graph, pos, edge_labels=edge_labels, font_color='blue')

        plt.title("Pseudocode AST Graph Visualization")
        plt.axis('off')
        plt.show()

######################################################################

#################### 檔案: Static/StructureAnalyzer.py ####################
import os
import math
import networkx as nx
from collections import defaultdict
import ASTGraph, PythonSourceParser

class StructureAnalyzer:
    def __init__(self, work_dir: str):
        self.work_dir = work_dir
        # 識別專案內部的模組清單 (用於區分內部依賴與第三方函式庫)
        self.internal_modules = self._get_internal_modules(work_dir)
        # 儲存每個模組的 ASTGraph 快取: { module_name: ASTGraph }
        self.graphs = {}
        # 儲存模組間依賴關係 (用於 Instability): { module_name: set(imported_modules) }
        self.dependencies = defaultdict(set)

        # 初始化時自動執行預處理
        self._preprocess()

    def _get_internal_modules(self, work_dir):
        """掃描目錄建立內部模組白名單"""
        mods = set()
        for root, _, files in os.walk(work_dir):
            for file in files:
                if file.endswith(".py") and file != "__init__.py":
                    # 將路徑轉換為 Python 模組表示法 (e.g., utils.helper)
                    rel_path = os.path.relpath(os.path.join(root, file), work_dir)
                    mod_name = rel_path.replace(os.sep, ".")[:-3]
                    mods.add(mod_name)
                    # 同時加入頂層包名
                    if "." in mod_name:
                        mods.add(mod_name.split('.')[0])
        return mods

    def _preprocess(self):
        """
        一次性解析所有檔案：
        1. 建立 ASTGraph 快取
        2. 建立全域模組依賴圖 (Global Dependency Graph)
        """
        for root, _, files in os.walk(self.work_dir):
            for file in files:
                if file.endswith(".py"):
                    path = os.path.join(root, file)
                    # 取得模組名稱
                    rel_path = os.path.relpath(path, self.work_dir)
                    mod_name = rel_path.replace(os.sep, ".")[:-3]
                    if file == "__init__.py": # 處理 package
                        mod_name = rel_path.replace(os.sep, ".")[:-12]

                    # 解析程式碼
                    with open(path, 'r', encoding='utf-8') as f:
                        code = f.read()

                    graph = ASTGraph.ASTGraph()
                    analyzer = PythonSourceParser.PythonSourceParser(graph)
                    analyzer.analyze_code(code)

                    self.graphs[mod_name] = graph

                    # 提取依賴關係 (僅針對內部模組)
                    for _, data in graph.graph.nodes(data=True):
                        if data.get('type') == 'import':
                            # 這裡簡化處理 import 字串解析
                            imp_str = data.get('label', '')
                            # 簡單啟發式解析：分割字串並比對白名單
                            for token in imp_str.replace(',', ' ').split():
                                clean_token = token.split('.')[0]
                                if clean_token in self.internal_modules and clean_token != mod_name:
                                    self.dependencies[mod_name].add(clean_token)

    # --- 1. 耦合度 (Coupling) [跨模組] ---
    def calculateCoupling(self, module_name: str) -> float:
        """
        計算指數遞減評分。
        公式: Score = 100 * e^(-0.2 * Ce)
        Ce (Efferent Coupling): 該模組依賴了多少個內部模組。
        """
        if module_name not in self.dependencies:
            return 100.0

        ce = len(self.dependencies[module_name])
        # 使用指數遞減函數，讓高耦合的懲罰加劇
        return round(100.0 * math.exp(-0.2 * ce), 2)

    # --- 2. 內聚性 (LCOM4) [模組內] ---
    # 修改 calculateCohesion
    def calculateCohesion(self, module_name: str) -> dict:
        """
        計算 LCOM4 與 連接密度 (Density)。
        Returns: { 'ClassName': {'lcom4': int, 'density': float} }
        """
        graph = self.graphs.get(module_name)
        if not graph: return {}

        results = {}
        class_nodes = [d for _, d in graph.graph.nodes(data=True) if d.get('type') == 'class']

        for cls in class_nodes:
            cls_name = cls.get('name')

            # 1. 建立方法關聯圖
            methods = []
            method_usage = defaultdict(set)

            for _, d in graph.graph.nodes(data=True):
                # 找出方法
                if d.get('type') == 'function' and d.get('parent_class') == cls_name:
                    methods.append(d.get('name'))
                # 找出屬性使用
                if d.get('parent_class') == cls_name and d.get('parent_method'):
                    fields = d.get('accessed_fields', [])
                    for f in fields:
                        method_usage[d.get('parent_method')].add(f)

            # 無方法或單一方法，視為完美內聚
            if len(methods) <= 1:
                results[cls_name] = {'lcom4': 1, 'density': 1.0}
                continue

            m_graph = nx.Graph()
            m_graph.add_nodes_from(methods)

            actual_edges = 0
            for i in range(len(methods)):
                for j in range(i + 1, len(methods)):
                    m1, m2 = methods[i], methods[j]
                    if not method_usage[m1].isdisjoint(method_usage[m2]):
                        m_graph.add_edge(m1, m2)
                        actual_edges += 1

            # 2. 計算 LCOM4 (連通分量數)
            lcom4 = nx.number_connected_components(m_graph)

            # 3. [新增] 計算連接密度 (Density)
            # Max Edges = n * (n-1) / 2
            n = len(methods)
            max_edges = (n * (n - 1)) / 2
            density = 0.0
            if max_edges > 0:
                density = round(actual_edges / max_edges, 2)

            results[cls_name] = {'lcom4': lcom4, 'density': density}

        return results

    # --- 3. 穩定性 (Instability) [模組間] ---
    def calculateInstability(self, module_name: str) -> float:
        """
        計算穩定性指標 I。
        公式: I = Ce / (Ca + Ce)
        範圍: [0, 1]。0=穩定(負責被依賴), 1=不穩定(負責變更)
        """
        if module_name not in self.graphs: return 0.0

        # Ce (Efferent): 我依賴了誰 (Outgoing)
        ce = len(self.dependencies[module_name])

        # Ca (Afferent): 誰依賴了我 (Incoming)
        # 這需要遍歷全域依賴表
        ca = 0
        for other_mod, imports in self.dependencies.items():
            if other_mod != module_name and module_name in imports:
                ca += 1

        if (ca + ce) == 0:
            return 0.5 # 既不依賴人也沒人依賴，中性

        return round(ce / (ca + ce), 2)

    # --- 4. 抽象度 (Abstractness) [模組內] ---
    def calculateAbstractness(self, module_name: str) -> float:
        """
        計算抽象度 A。
        公式: A = 抽象類別數 / 總類別數
        範圍: [0, 1]
        """
        graph = self.graphs.get(module_name)
        if not graph: return 0.0

        total_classes = 0
        abstract_classes = 0

        for _, d in graph.graph.nodes(data=True):
            if d.get('type') == 'class':
                total_classes += 1
                # 檢查前置步驟中提取的 is_abstract 標記
                if d.get('is_abstract', False):
                    abstract_classes += 1

        if total_classes == 0:
            return 0.0

        return round(abstract_classes / total_classes, 2)


    # --- [新增] 虛擬靜態分析 (Phase 2 Check) ---
    def detect_cycles_from_stubs(self, virtual_code_map: dict) -> list:
        """
        基於虛擬代碼 map { 'mod_name': 'import a\nimport b' } 檢測循環依賴。
        Returns: list of cycles (e.g. [['a', 'b', 'a']])
        """
        temp_graph = nx.DiGraph()

        for mod, code in virtual_code_map.items():
            temp_graph.add_node(mod)
            # 簡單解析 import
            for line in code.splitlines():
                if line.startswith("import "):
                    target = line.split(" ")[1].strip()
                    temp_graph.add_edge(mod, target)
                elif line.startswith("from "):
                    parts = line.split(" ")
                    if len(parts) >= 2:
                        target = parts[1].strip().split('.')[0] # 取頂層模組
                        temp_graph.add_edge(mod, target)

        try:
            return list(nx.simple_cycles(temp_graph))
        except:
            return []

    # --- [新增] 實作一致性檢查 (Phase 3 Check) ---
    def verify_implementation_deps(self, code_path: str, allowed_deps: list) -> bool:
        """
        解析真實 Python 檔案，確認其 import 是否超出 allowed_deps 範圍。
        """
        try:
            with open(code_path, 'r', encoding='utf-8') as f:
                code = f.read()

            # 使用 ASTGraph 解析
            g = ASTGraph.ASTGraph()
            p = PythonSourceParser.PythonSourceParser(g)
            p.analyze_code(code)

            actual_imports = set()
            for _, data in g.graph.nodes(data=True):
                if data.get('type') == 'import':
                    label = data.get('label', '')
                    # 處理 "from x import y" 或 "import x"
                    # 簡化邏輯：抓第一個 token
                    token = label.replace("from ", "").replace("import ", "").split(" ")[0].split('.')[0]
                    actual_imports.add(token)

            # 檢查是否違反 (忽略標準庫，這裡假設 internal_modules 已正確填充)
            # 若 internal_modules 為空，需重新初始化
            if not self.internal_modules:
                self._preprocess()

            for imp in actual_imports:
                # 如果是專案內部的模組，但不在允許列表內 -> 違規
                if imp in self.internal_modules and imp not in allowed_deps:
                    # 排除自己
                    # 取得 code_path 所屬模組名...這裡簡化，假設呼叫者會處理
                    print(f"[Audit] Violation: Imported '{imp}' but only {allowed_deps} allowed.")
                    return False

            return True

        except Exception as e:
            print(f"[Audit Error] {e}")
            return False # 保守策略：分析失敗視為失敗

######################################################################

#################### 檔案: Static/CodeAnalyzer.py ####################
import radon.complexity as radon_cc
import radon.metrics as radon_metrics
import radon.raw as radon_raw
from radon.visitors import ComplexityVisitor

class CodeAnalyzer:
    """
    CodeAnalyzer: 專注於「程式碼層級」的指標計算。
    完全封裝 radon 套件，負責計算單一檔案或程式碼片段的統計數據。
    """
    def __init__(self, source_code: str):
        """
        Args:
            source_code (str): 待分析的原始碼字串。
        """
        self.code = source_code

    # --- 1. 迴圈複雜度 (Cyclomatic Complexity) ---
    def calculateComplexity(self) -> dict:
        """
        計算程式碼中每個函式/方法的圈複雜度 (CC)。

        Returns:
            dict: { 'function_name': cc_score (int) }
            若程式碼中無函式，則回傳空字典。
        """
        results = {}
        try:
            # cc_visit 會自動解析 AST 並找出所有區塊 (Function/Class)
            blocks = radon_cc.cc_visit(self.code)

            for block in blocks:
                # 只關注函式與方法 (Function & Method)
                # 若 block 是 Class，通常我們看它內部的方法
                if hasattr(block, 'type') and block.type in ('function', 'method'):
                    # 若有重名函式 (如不同類別中的同名方法)，這裡做簡單處理
                    # 實際應用可結合 lineno 作為 key
                    name = block.name
                    if hasattr(block, 'classname') and block.classname:
                        name = f"{block.classname}.{block.name}"

                    results[name] = block.complexity
        except Exception as e:
            print(f"[Radon CC Error]: {e}")

        return results

    # --- 2. Halstead 複雜度 (Halstead Metrics) ---
    def calculateHalstead(self) -> dict:
        """
        計算 Halstead 指標 (體積 Volume, 難度 Difficulty, 工作量 Effort)。
        這通常是針對整段傳入的代碼計算。
        """
        try:
            h_metrics = radon_metrics.h_visit(self.code)
            # h_visit 回傳的是一個 named tuple，包含 total 和 functions 屬性
            # 這裡我們回傳整體的統計
            return {
                'volume': round(h_metrics.total.volume, 2),
                'difficulty': round(h_metrics.total.difficulty, 2),
                'effort': round(h_metrics.total.effort, 2)
            }
        except Exception:
            # 可能是語法錯誤或空檔案
            return {'volume': 0, 'difficulty': 0, 'effort': 0}

    # --- 3. 原始碼統計 (Raw Metrics / SLOC) ---
    def calculateRawMetrics(self) -> dict:
        """
        計算 LOC (總行數), LLOC (邏輯行數), SLOC (原始碼行數 - 去除空行註解), Comments (註解行數)。
        """
        try:
            raw = radon_raw.analyze(self.code)
            return {
                'loc': raw.loc,           # Total lines
                'lloc': raw.lloc,         # Logical lines
                'sloc': raw.sloc,         # Source lines (Code only)
                'comments': raw.comments, # Comment lines
                'blank': raw.blank        # Blank lines
            }
        except Exception:
            return {'loc': 0, 'lloc': 0, 'sloc': 0, 'comments': 0, 'blank': 0}

    # --- 4. 維護性指標 (Maintainability Index) ---
    def calculateMaintainability(self) -> float:
        """
        計算維護性指標 (MI)。範圍 0-100，越高越好。
        < 65: 低 (難以維護)
        65-85: 中
        > 85: 高 (易於維護)
        """
        try:
            # multi=True 表示支援多行字串計算
            mi_score = radon_metrics.mi_visit(self.code, multi=True)
            return round(mi_score, 2)
        except Exception:
            return 0.0

######################################################################

#################### 檔案: Static/PythonSourceParser.py ####################
import ast
from typing import List

# 假設上一段程式碼儲存在 ast_graph.py，或是直接在此檔案上方定義了 ASTGraph
# from ast_graph import ASTGraph

class PythonSourceParser:
    """
    分析 Python 原始碼並將其轉換為 ASTGraph 流程圖結構。
    """
    def __init__(self, graph_instance):
        self.graph = graph_instance
        # 新增狀態堆疊，用於記錄當前處於哪個 Class 或 Function 內
        self.current_class = None
        self.current_method = None
        self.source_lines = []  # [新增] 用於儲存原始碼行
    def _connect_with_context(self, src, target):
        """智能連接：若來源是條件或迴圈節點且尚未有 True 路徑，則自動標記為 No"""
        label = None
        src_node = self.graph.get_node_info(src)

        # 檢查來源節點是否為條件判斷或迴圈
        if src_node and src_node.get('type') in ['condition', 'loop']:
            # 檢查是否已有 Yes/True 路徑
            has_true = False
            for _, _, data in self.graph.graph.out_edges(src, data=True):
                if data.get('label') in ['Yes', 'True']:
                    has_true = True

            # 如果有 True 路徑，則這條新建立的邊應該是 False (No) 路徑
            if has_true:
                label = "No"

        self.graph.add_edge(src, target, condition=label)

    def analyze_code(self, source_code: str):
        """
        解析原始碼字串並填充 Graph。
        """
        # 1. 使用 Python 內建 AST 解析原始碼
        try:
            self.source_lines = source_code.splitlines()
            tree = ast.parse(source_code)
        except SyntaxError as e:
            print(f"Syntax Error in source code: {e}")
            return

        # 2. 建立起點
        start_node_id = self.graph.add_node("Program Start", node_type="start")

        # 3. 開始遞迴處理主要區塊
        # incoming_ids 代表「上一層流下來的節點 ID 列表」
        final_leaves = self._process_block(tree.body, [start_node_id])

        # 4. 建立終點並連接所有剩餘的葉節點
        end_node_id = self.graph.add_node("Program End", node_type="end")
        for leaf in final_leaves:
            self.graph.add_edge(leaf, end_node_id)

    def _process_block(self, statements: List[ast.stmt], incoming_ids: List[str]) -> List[str]:
        """
        遞迴處理一連串的語句 (Statements)。

        Args:
            statements: AST 語句列表
            incoming_ids: 上一步驟的節點 ID 列表 (可能有從多個分支匯合而來)

        Returns:
            outgoing_ids: 這一區塊執行完後，最末端的節點 ID 列表
        """
        current_incoming = incoming_ids

        for stmt in statements:
            # 針對每一個語句，處理並更新 current_incoming
            # 因為這個語句的輸出，將成為下一個語句的輸入
            current_incoming = self._process_statement(stmt, current_incoming)

        return current_incoming

    # [新增] 輔助函式：計算真實行數
    def _count_real_loc(self, start_line, end_line):
        if start_line is None or end_line is None:
            return 0

        # Python 行號從 1 開始，List 索引從 0 開始
        lines = self.source_lines[start_line-1 : end_line]
        real_count = 0
        for line in lines:
            stripped = line.strip()
            # 過濾空行與單行註解
            if stripped and not stripped.startswith('#'):
                real_count += 1
        return real_count

    def _process_statement(self, stmt: ast.stmt, incoming_ids: List[str]) -> List[str]:
        """
        處理單一語句，根據類型分派邏輯。
        回傳該語句結束後的所有「出口節點」。
        """

        # 1. 處理 If (分支)
        if isinstance(stmt, ast.If):
            condition_text = f"If {ast.unparse(stmt.test)}?"
            decision_id = self.graph.add_node(condition_text, node_type="decision")

            # 連接入口到這個判斷點
            for src in incoming_ids:
                self.graph.add_edge(src, decision_id)

            # 處理 True 路徑 (Body)
            true_leaves = self._process_block(stmt.body, [decision_id])
            # 為 True 路徑的第一步加上標籤 (我們需要手動修正第一條邊的 label)
            # 注意：這裡簡化處理，直接假設 _process_block 的第一個節點連接邏輯
            # 更嚴謹的做法是在 add_edge 時指定，但因為 block 內部邏輯封裝，
            # 我們可以簡單地在此層級標記：從 decision 出去的 edge 若連向 true_block 的頭，標記 Yes
            # (為了保持簡單，這裡我們用後處理或假設 logic 是對的，下面用更直接的方式)

            # --- 修正連接邏輯：我們需要明確知道分支的第一步是誰 ---
            # 由於 _process_block 依賴 incoming_ids 自動連線，我們很難在外部插入 "Yes" 標籤。
            # 所以我們改變策略：手動處理分支的第一步連線。

            # 重構分支連線：
            # A. 處理 True Block
            if stmt.body:
                # 手動取出第一句建立節點，為了加上 "Yes" 標籤
                first_true_stmt = stmt.body[0]
                # 遞迴呼叫單句處理，但這次 incoming 是空的，我們手動連
                # 這裡為了避免遞迴邏輯太複雜，我們簡化：
                # 讓 decision_id 傳入，但在 graph 內部，我們無法輕易修改剛建立的邊。
                # 最好的方式：_process_block 支援傳入 edge label?
                # 或者：我們在這裡手動連線 "Yes"。

                # 簡單做法：使用我們封裝的邏輯，但在這裡特例處理 True/False 標籤
                # 我們先建立邊，再讓 block 處理後續
                pass

            # 為了程式碼簡潔與穩健，我們使用較通用的方式：
            # 將 Decision 節點視為目前的 incoming，但我們需要在 Edge 上加屬性。
            # 因為 _process_block 會自動 add_edge，我們需要攔截那個行為，或者修改 ASTGraph。
            # 這裡採取「後修正」策略，或者在 `_process_block` 傳入 condition label。

            # 讓我們採用更直觀的「手動分派」：

            # Path 1: True
            # 找出 Body 的第一個實際節點有點難，所以我們加入一個「虛擬節點」或者直接解析
            # 這裡使用最簡單的 hack: 在 ASTGraph 增加 update_edge 或者我們接受沒有 Yes/No 標籤，
            # 但為了達到要求，我們手動處理第一層。

            # 取得 True Block 的結果
            # 先建立一個 Dummy 連接點或直接連線?
            # 我們直接在這裡呼叫 _process_block，傳入 [decision_id]。
            # 然後遍歷 graph 找出剛才 decision_id 連出去的邊，標上 "Yes"。
            true_exits = self._process_block(stmt.body, [decision_id])
            self._label_edges_from(decision_id, "Yes", exclude_existing=True) # 假設有這個輔助函式

            # Path 2: False (Else)
            false_exits = []
            if stmt.orelse:
                # 記錄目前的邊數量，以便區分新增的邊
                false_exits = self._process_block(stmt.orelse, [decision_id])
                self._label_edges_from(decision_id, "No", exclude_label="Yes")
            else:
                # 如果沒有 else，False 路徑直接流出 (即 decision 節點本身也是出口之一)
                # 但這代表 decision 連向「下一個語句」。
                # 我們把 decision_id 加入 false_exits
                false_exits = [decision_id]
                # 這條邊會在下一個語句被建立，標籤怎麼辦？
                # 這是一個典型的流程圖繪製難題。
                # 解決方案：回傳 (id, edge_label_for_next)
                pass

            return true_exits + false_exits

        # 2. 處理 While (迴圈)
        elif isinstance(stmt, ast.While):
            condition_text = f"While {ast.unparse(stmt.test)}?"
            decision_id = self.graph.add_node(condition_text, node_type="decision")

            for src in incoming_ids:
                self.graph.add_edge(src, decision_id)

            # Body
            body_exits = self._process_block(stmt.body, [decision_id])
            self._label_edges_from(decision_id, "True", exclude_existing=True)

            # Loop back: 將 body 的出口連回 decision
            for leaf in body_exits:
                self.graph.add_edge(leaf, decision_id)

            # While 的出口是當條件為 False 時，直接從 Decision 出去
            # 我們需要標記這條未來的邊為 False
            # 這裡我們做一個 trick: 回傳一個 tuple (id, condition) 給上層？
            # 或者簡單地，我們在外部標記。
            # 為了保持介面簡單，這裡回傳 decision_id，
            # 並期待 _process_block 的下一次迭代會連線。
            # 我們預先在這裡設定一個屬性給 decision_id 說「下一條邊是 False」比較困難。
            # 簡單解法：While False 出口就是 decision_id。標籤在 ASTGraph 繪圖時可能顯示不出來，除非我們特別處理。
            return [decision_id]
        elif isinstance(stmt, ast.For):
            # 1. 解析迴圈變數與迭代範圍
            target = ast.unparse(stmt.target)   # 例如 "i"
            iterator = ast.unparse(stmt.iter)   # 例如 "range(10)"
            condition_text = f"For {target} in {iterator}?"

            # 2. 建立迴圈節點 (類型設為 loop)
            loop_id = self.graph.add_node(condition_text, node_type="loop")

            # 3. 將上一步驟連入此迴圈節點
            for src in incoming_ids:
                self._connect_with_context(src, loop_id)

            # 4. 處理迴圈內部 (True/Yes 路徑)
            body_exits = self._process_block(stmt.body, [loop_id])
            self._label_edges_from(loop_id, "True", exclude_existing=True)

            # 5. Loop Back: 將迴圈內部的終點連回開頭
            for leaf in body_exits:
                self.graph.add_edge(leaf, loop_id)

            # 6. 處理 for-else 語法 (Python 特有，若迴圈正常結束則執行)
            if stmt.orelse:
                # 如果有 else，False 路徑進入 else block
                orelse_exits = self._process_block(stmt.orelse, [loop_id])
                self._label_edges_from(loop_id, "False", exclude_label="True")
                return orelse_exits

            # 7. 若無 else，迴圈結束後直接往下一步走 (False 路徑)
            # 下一個指令的 source 就是這個 loop_id
            return [loop_id]
        # 3. 處理基本語句 (Assignment, Expr, Return, Print)
        elif isinstance(stmt, (ast.Import, ast.ImportFrom)):
            # 1. 取得語句內容 (如 "import math" 或 "from os import path")
            content = ast.unparse(stmt)

            # 2. 建立節點，類型設為 "import"
            node_id = self.graph.add_node(content, node_type="import")

            # 3. 連接上下文 (從上一步驟流向此 Import)
            for src in incoming_ids:
                self._connect_with_context(src, node_id)

            # Import 執行完後，流程繼續往下
            return [node_id]

        elif isinstance(stmt, (ast.FunctionDef, ast.AsyncFunctionDef)):
            # [新增] 取得結束行號 (Python 3.8+)
            end_lineno = getattr(stmt, 'end_lineno', stmt.lineno)

            # [關鍵修改] 呼叫計算函式
            real_loc = self._count_real_loc(stmt.lineno, end_lineno)

            # [關鍵修改] add_node 時傳入詳細資訊
            func_id = self.graph.add_node(
                f"def {stmt.name}",
                node_type="function",
                name=stmt.name,                   # 用於 LOC 識別
                lineno=stmt.lineno,               # 用於 LOC 計算
                end_lineno=end_lineno,            # 用於 LOC 計算
                real_loc=real_loc,        # [新增] 儲存過濾後的行數
                parent_class=self.current_class   # 用於 LCOM4 歸屬
            )

            for src in incoming_ids:
                self._connect_with_context(src, func_id)

            # [新增] 更新 Context 並遞迴
            prev_method = self.current_method
            self.current_method = stmt.name
            self._process_block(stmt.body, [func_id])
            self.current_method = prev_method

            return [func_id]

        elif isinstance(stmt, ast.ClassDef):
            # --- 抽象度分析邏輯 ---
            is_abstract = False
            # 1. 檢查繼承 (Bases): 是否繼承 'ABC'
            for base in stmt.bases:
                if isinstance(base, ast.Name) and base.id == 'ABC':
                    is_abstract = True
                    break
                # (進階可檢查 attribute access 如 abc.ABC)

            # 2. 檢查方法裝飾器 (Decorators): 是否有 @abstractmethod
            if not is_abstract:
                for node in ast.walk(stmt):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        for decorator in node.decorator_list:
                            # 檢查 @abstractmethod 或 @abc.abstractmethod
                            if (isinstance(decorator, ast.Name) and decorator.id == 'abstractmethod') or \
                               (isinstance(decorator, ast.Attribute) and decorator.attr == 'abstractmethod'):
                                is_abstract = True
                                break
                    if is_abstract: break

            # [關鍵修改] add_node 時傳入 name, lineno, is_abstract
            class_id = self.graph.add_node(
                f"class {stmt.name}",
                node_type="class",
                name=stmt.name,            # 用於 LCOM4 識別
                lineno=stmt.lineno,        # 用於 LOC (雖然類別通常不用 LOC，但為了完整性)
                is_abstract=is_abstract    # 用於抽象度計算 (請確認 is_abstract 變數已計算)
            )

            for src in incoming_ids:
                self._connect_with_context(src, class_id)

            # [新增] 更新 Context 並遞迴
            prev_class = self.current_class
            self.current_class = stmt.name # 設定當前類別
            self._process_block(stmt.body, [class_id])
            self.current_class = prev_class # 還原

            return [class_id]

        else:
            # --- 新增修改：過濾 Docstring / 多行註解 ---
            # 檢查語句是否為 ast.Expr (表達式)，且其內容為 ast.Constant (常數)，且值為字串
            # Python 3.8+ 使用 ast.Constant, 舊版可能需檢查 ast.Str (此處以新版標準為主)
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Constant) and isinstance(stmt.value.value, str):
                # 如果是獨立的字串常數 (即多行註解)，直接略過。
                # 回傳 incoming_ids，代表「上一個節點」的流向直接傳遞給「下一個語句」，
                # 就像這個註解節點不存在一樣。
                return incoming_ids
            # ---------------------------------------
# [新增] LCOM4 關鍵：提取使用的實例屬性 (Field Access)
            used_fields = set()
            if self.current_class and self.current_method:
                for node in ast.walk(stmt):
                    # 尋找 self.xxx 的模式
                    if isinstance(node, ast.Attribute):
                        if isinstance(node.value, ast.Name) and node.value.id == 'self':
                            used_fields.add(node.attr)
            # --------------------------------------------------
            content = ast.unparse(stmt)

            # 簡單判斷是否為 I/O (Print 或 Input)
            is_io = False
            # 檢查是否為 print() 呼叫
            if isinstance(stmt, ast.Expr) and isinstance(stmt.value, ast.Call):
                func_name = getattr(stmt.value.func, 'id', '')
                if func_name == 'print':
                    is_io = True
            # 檢查賦值語句右邊是否有 input()
            elif isinstance(stmt, ast.Assign):
                if isinstance(stmt.value, ast.Call) and getattr(stmt.value.func, 'id', '') == 'input':
                    is_io = True
                # 處理 int(input(...)) 的巢狀情況
                elif isinstance(stmt.value, ast.Call) and isinstance(stmt.value.func, ast.Name) and stmt.value.func.id in ('int', 'float', 'str'):
                     if stmt.value.args and isinstance(stmt.value.args[0], ast.Call) and getattr(stmt.value.args[0].func, 'id', '') == 'input':
                        is_io = True

            n_type = "io" if is_io else "process" # 假設 is_io 已計算

            node_id = self.graph.add_node(
                content,
                node_type=n_type,
                lineno=stmt.lineno,             # LOC 支援
                parent_class=self.current_class, # LCOM4 支援 (方便追蹤)
                parent_method=self.current_method,
                accessed_fields=list(used_fields) # LCOM4 支援：記錄此節點用到的屬性
            )

            for src in incoming_ids:
                self._connect_with_context(src, node_id)

            return [node_id]

    def _label_edges_from(self, source_id, label, exclude_existing=False, exclude_label=None):
        """
        輔助函式：為剛建立的邊加上標籤。
        這是為了解決遞迴建立節點時，難以即時傳入 Edge Label 的問題。
        """
        edges = self.graph.graph.out_edges(source_id, data=True)
        for u, v, data in edges:
            if exclude_existing and 'label' in data:
                continue
            if exclude_label and data.get('label') == exclude_label:
                continue

            # NetworkX 的邊屬性更新
            self.graph.graph[u][v]['label'] = label

######################################################################
